{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2734496,"sourceType":"datasetVersion","datasetId":1654566},{"sourceId":7669478,"sourceType":"datasetVersion","datasetId":4473093}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## FineTuning ","metadata":{}},{"cell_type":"code","source":"import time\n\ndef measure_single_token_generation_time(target_model, tokenizer, device, prompt=\"Test prompt\"):\n    \"\"\"\n    Measures the time taken by the target model to generate a single token.\n\n    Args:\n        target_model (AutoModelForCausalLM): The target language model.\n        tokenizer (AutoTokenizer): The tokenizer associated with the model.\n        device (str): The device to run the model on ('cuda' or 'cpu').\n        prompt (str): The prompt to start generation from. Defaults to \"Test prompt\".\n\n    Returns:\n        float: The average time taken for single token generation (in seconds).\n    \"\"\"\n    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n    attention_mask = torch.ones_like(input_ids)\n\n    # Warm-up to ensure fair timing\n    with torch.no_grad():\n        _ = target_model(input_ids, attention_mask=attention_mask)\n\n    # Measure time for single token generation\n    num_runs = 100  # Number of repetitions for averaging\n    total_time = 0\n\n    for _ in range(num_runs):\n        start_time = time.time()\n        with torch.no_grad():\n            outputs = target_model(input_ids, attention_mask=attention_mask, return_dict=True)\n            logits = outputs.logits[:, -1, :]  # Logits for the last token\n            _ = torch.argmax(logits, dim=-1)  # Simulate single token prediction\n        end_time = time.time()\n        total_time += (end_time - start_time)\n\n    avg_time_per_token = total_time / num_runs\n    print(f\"Average time per token (single token generation): {avg_time_per_token:.6f} seconds\")\n    return avg_time_per_token\n\n# Example usage\n# Instantiate SpeculativeDecoder and measure single token time\ndecoder = SpeculativeDecoder(target_model_name=\"EleutherAI/gpt-neo-1.3B\", draft_model_name=\"distilgpt2\")\nsingle_token_time = measure_single_token_generation_time(\n    decoder.Mp, decoder.tokenizer, decoder.device\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:21:05.496426Z","iopub.execute_input":"2024-11-17T18:21:05.496855Z","iopub.status.idle":"2024-11-17T18:21:52.472325Z","shell.execute_reply.started":"2024-11-17T18:21:05.496801Z","shell.execute_reply":"2024-11-17T18:21:52.471106Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2253d1e68c96493d830a4852c68c36b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.31G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f3778d7702c49bda76f49aac8b4578d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58d7e9a2c8104d8b917de1b5285dd2fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"223ce8f197ff496381003828cc9a8a28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"addda944495649438611bea10933d8aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bff8ed1f6a9498e8691f5f2e5209ca5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d2b379b9db6425daab00f1945cd7c8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e831becba234c36946b2b588b46116b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d03a6e3ba9248089fbd048168774deb"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Average time per token (single token generation): 0.035139 seconds\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset\nfrom transformers import (\n    GPT2LMHeadModel,\n    GPT2Tokenizer,\n    Trainer,\n    TrainingArguments,\n    DataCollatorForLanguageModeling\n)\nfrom datasets import load_dataset\nimport argparse\n\n# Import required libraries\nimport os\nimport argparse\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling, set_seed\nfrom datasets import load_dataset\nfrom torch.utils.data import Dataset\n\n# Define the dataset class\n\n# Set random seed for reproducibility\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2024-11-20T21:10:09.357792Z","iopub.execute_input":"2024-11-20T21:10:09.358463Z","iopub.status.idle":"2024-11-20T21:10:27.281303Z","shell.execute_reply.started":"2024-11-20T21:10:09.358430Z","shell.execute_reply":"2024-11-20T21:10:27.280399Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class CNNDailyMailGPT2Dataset(Dataset):\n    def __init__(self, data, tokenizer, max_length, prompt_prefix=\"summarize: \"):\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.prompt_prefix = prompt_prefix\n        self.data = data\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        article = self.data[idx]['article']\n        highlights = self.data[idx]['highlights']\n        input_text = self.prompt_prefix + article\n        target_text = highlights\n\n        input_tokens = self.tokenizer.encode_plus(\n            input_text, max_length=self.max_length, truncation=True, padding='max_length', return_tensors='pt'\n        )\n        target_tokens = self.tokenizer.encode_plus(\n            target_text, max_length=self.max_length, truncation=True, padding='max_length', return_tensors='pt'\n        )\n\n        input_ids = input_tokens['input_ids'].squeeze()\n        attention_mask = input_tokens['attention_mask'].squeeze()\n        labels = target_tokens['input_ids'].squeeze()\n\n        return {\n            'input_ids': input_ids,\n            'attention_mask': attention_mask,\n            'labels': labels\n        }","metadata":{"execution":{"iopub.status.busy":"2024-11-17T17:56:28.870652Z","iopub.execute_input":"2024-11-17T17:56:28.871380Z","iopub.status.idle":"2024-11-17T17:56:28.880377Z","shell.execute_reply.started":"2024-11-17T17:56:28.871334Z","shell.execute_reply":"2024-11-17T17:56:28.879495Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"model_name = 'distilgpt2'  # Modify to 'gpt2', 'gpt2-large', etc. as needed\n\nbatch_size = 4\nmax_length = 1024\nepochs = 1\nseed = 42\n# Set up argument parsing for Kaggle notebook\noutput_dir = f'/kaggle/working/{model_name}_epochs{epochs}_batch{batch_size}_max_len{max_length}'  # Kaggle's working directory for output\nos.makedirs(output_dir, exist_ok=True)\n\n\n# Set random seed\nset_seed(seed)\n\n# Load dataset from Hugging Face\ndataset = load_dataset('cnn_dailymail', '3.0.0')\n\n\n\ntrain_data = dataset['train']\nval_data = dataset['validation']\n\n# Limit train_data to the first 10,000 samples\n# train_data = train_data.select(range(50000))\nval_data = val_data.select(range(3000))\n# Initialize tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\n\n# Create datasets\ntrain_dataset = CNNDailyMailGPT2Dataset(train_data, tokenizer, max_length)\n\nval_dataset = CNNDailyMailGPT2Dataset(val_data, tokenizer, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T17:22:10.126175Z","iopub.execute_input":"2024-11-19T17:22:10.126842Z","iopub.status.idle":"2024-11-19T17:22:26.497650Z","shell.execute_reply.started":"2024-11-19T17:22:10.126807Z","shell.execute_reply":"2024-11-19T17:22:26.495483Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/15.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91e4e1b487c34bfb9343921bb81328d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5853ac9973454f4ba6c67f81b475cc8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cd71cb4289a4a0f8d2cd64c415d9dd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00002-of-00003.parquet:   0%|          | 0.00/259M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b802210e764e48899020441085ab5849"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/34.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf2c1abe7a454cbbbcb08838dbba061a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/30.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eed9adb6f8c54a44b6ef81f53365d66a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f6db0ef059f4af4b77c5c71e9b3b546"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5e620e8af8d4d4b8730de921b7c69f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e5fe2cdf27a40909b2cad896f4b59cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dcdb6ef1abc451482c76f8a463afcc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2892e1a8bc474b668ee03ba94f124587"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45ed6057b89942b18d68e0e8641d8a44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66859fccf3da4beb82d680a8807ede40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4e6fed79ba94a3a9524cb5a19102029"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Create datasets\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCNNDailyMailGPT2Dataset\u001b[49m(train_data, tokenizer, max_length)\n\u001b[1;32m     33\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m CNNDailyMailGPT2Dataset(val_data, tokenizer, max_length)\n","\u001b[0;31mNameError\u001b[0m: name 'CNNDailyMailGPT2Dataset' is not defined"],"ename":"NameError","evalue":"name 'CNNDailyMailGPT2Dataset' is not defined","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"len(val_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:53:53.906133Z","iopub.execute_input":"2024-11-15T17:53:53.906849Z","iopub.status.idle":"2024-11-15T17:53:53.913342Z","shell.execute_reply.started":"2024-11-15T17:53:53.906803Z","shell.execute_reply":"2024-11-15T17:53:53.912384Z"},"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"3000"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Initialize model\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\nmodel.resize_token_embeddings(len(tokenizer))\n\n# Define data collator\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False,\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:53:53.914678Z","iopub.execute_input":"2024-11-15T17:53:53.915449Z","iopub.status.idle":"2024-11-15T17:53:55.977549Z","shell.execute_reply.started":"2024-11-15T17:53:53.915405Z","shell.execute_reply":"2024-11-15T17:53:55.976644Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e48a2f1e5790426288ebce76935f68f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c836dc156bb343708366ff5f07523267"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=output_dir,\n    num_train_epochs=epochs,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=10,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n)\n\n# Create Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)\n\n# Train model\ntrainer.train()\n\n# Save the model and tokenizer\ntrainer.save_model(output_dir)\ntokenizer.save_pretrained(output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:53:55.978775Z","iopub.execute_input":"2024-11-15T17:53:55.979150Z","iopub.status.idle":"2024-11-15T17:54:36.280944Z","shell.execute_reply.started":"2024-11-15T17:53:55.979106Z","shell.execute_reply":"2024-11-15T17:54:36.279326Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='34' max='35890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   34/35890 00:33 < 10:20:48, 0.96 it/s, Epoch 0.00/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 28\u001b[0m\n\u001b[1;32m     18\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     19\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     20\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Save the model and tokenizer\u001b[39;00m\n\u001b[1;32m     31\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(output_dir)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2388\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2394\u001b[0m ):\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3485\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3485\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3487\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3490\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3491\u001b[0m ):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3532\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3530\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3531\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3532\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3533\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3534\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:187\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[1;32m    186\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_apply(replicas, inputs, module_kwargs)\n\u001b[0;32m--> 187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_device\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:204\u001b[0m, in \u001b[0;36mDataParallel.gather\u001b[0;34m(self, outputs, output_device)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgather\u001b[39m(\u001b[38;5;28mself\u001b[39m, outputs: Any, output_device: Union[\u001b[38;5;28mint\u001b[39m, torch\u001b[38;5;241m.\u001b[39mdevice]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/scatter_gather.py:109\u001b[0m, in \u001b[0;36mgather\u001b[0;34m(outputs, target_device, dim)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Recursive function calls like this create reference cycles.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Setting the function to None clears the refcycle.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mgather_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m     gather_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/scatter_gather.py:100\u001b[0m, in \u001b[0;36mgather.<locals>.gather_map\u001b[0;34m(outputs)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m outputs):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll dicts must have the same number of keys\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgather_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_namedtuple(out):\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(out)\u001b[38;5;241m.\u001b[39m_make(\u001b[38;5;28mmap\u001b[39m(gather_map, \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39moutputs)))\n","File \u001b[0;32m<string>:9\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, loss, logits, past_key_values, hidden_states, attentions, cross_attentions)\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:390\u001b[0m, in \u001b[0;36mModelOutput.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;66;03m# if we provided an iterator as first field and the iterator is a (key, value) iterator\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# set the associated fields\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_field_iterator:\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, element \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(iterator):\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    392\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(element, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m))\n\u001b[1;32m    393\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(element) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    394\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(element[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    395\u001b[0m         ):\n\u001b[1;32m    396\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    397\u001b[0m                 \u001b[38;5;66;03m# If we do not have an iterator of key/values, set it as attribute\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/scatter_gather.py:100\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m outputs):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll dicts must have the same number of keys\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(out)((k, \u001b[43mgather_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    101\u001b[0m                      \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m out)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_namedtuple(out):\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(out)\u001b[38;5;241m.\u001b[39m_make(\u001b[38;5;28mmap\u001b[39m(gather_map, \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39moutputs)))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/scatter_gather.py:94\u001b[0m, in \u001b[0;36mgather.<locals>.gather_map\u001b[0;34m(outputs)\u001b[0m\n\u001b[1;32m     92\u001b[0m out \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGather\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/function.py:574\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    573\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:75\u001b[0m, in \u001b[0;36mGather.forward\u001b[0;34m(ctx, target_device, dim, *inputs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     ctx\u001b[38;5;241m.\u001b[39munsqueezed_scalar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     74\u001b[0m ctx\u001b[38;5;241m.\u001b[39minput_sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(i\u001b[38;5;241m.\u001b[39msize(ctx\u001b[38;5;241m.\u001b[39mdim) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inputs)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_device\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/comm.py:235\u001b[0m, in \u001b[0;36mgather\u001b[0;34m(tensors, dim, destination, out)\u001b[0m\n\u001b[1;32m    228\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    229\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing -1 to represent CPU tensor is deprecated. Please use a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    230\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice object or string instead, e.g., \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    231\u001b[0m             \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    232\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    233\u001b[0m         )\n\u001b[1;32m    234\u001b[0m     destination \u001b[38;5;241m=\u001b[39m _get_device_index(destination, allow_cpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m destination \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"import shutil\nimport os\nfrom IPython.display import FileLink\n\n# Define the output directory you want to zip\noutput_dir = '/kaggle/working/model_output'  # Path to your model output folder\n\n# Zip the output directory\nshutil.make_archive(output_dir, 'zip', output_dir)\n\n# Now you can generate a clickable link to download the file\ndownload_link = FileLink(f'{output_dir}.zip')\n\n# Display the link to download the file\ndownload_link","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:54:36.281980Z","iopub.status.idle":"2024-11-15T17:54:36.282476Z","shell.execute_reply.started":"2024-11-15T17:54:36.282204Z","shell.execute_reply":"2024-11-15T17:54:36.282229Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## SpeculativeDecoder","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nimport time\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-11-20T21:10:27.282882Z","iopub.execute_input":"2024-11-20T21:10:27.283420Z","iopub.status.idle":"2024-11-20T21:10:27.290726Z","shell.execute_reply.started":"2024-11-20T21:10:27.283393Z","shell.execute_reply":"2024-11-20T21:10:27.289866Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class SpeculativeDecoder:\n    \"\"\"\n    A class implementing speculative decoding for language models.\n\n    This class uses a larger target model and a smaller draft model to perform\n    speculative decoding, potentially speeding up text generation.\n\n    Attributes:\n        device (str): The device to run the models on ('cuda' or 'cpu').\n        target_model (AutoModelForCausalLM): The larger, more accurate language model.\n        draft_model (AutoModelForCausalLM): The smaller, faster language model for draft predictions.\n        tokenizer (AutoTokenizer): The tokenizer for both models.\n    \"\"\"\n\n\n    def __init__(self, target_model_name, draft_model_name, device='cuda' if torch.cuda.is_available() else 'cpu'):\n        \"\"\"\n        Initialize the SpeculativeDecoder with target and draft models.\n\n        Args:\n            target_model_name (str): The name or path of the target (larger) model.\n            draft_model_name (str): The name or path of the draft (smaller) model.\n            device (str): The device to run the models on. Defaults to 'cuda' if available, else 'cpu'.\n        \"\"\"\n\n        self.device = device\n        self.Mp = AutoModelForCausalLM.from_pretrained(target_model_name).to(self.device)\n        self.Mq = AutoModelForCausalLM.from_pretrained(draft_model_name).to(self.device)\n        self.tokenizer = AutoTokenizer.from_pretrained(target_model_name)\n        self.no_accepted_tokens = 0\n        self.alpha = 0\n        self.total_time_taken = 0\n\n        if self.tokenizer.pad_token is None:\n            self.tokenizer.pad_token = self.tokenizer.eos_token\n\n        self.Mp.eval()\n        self.Mq.eval()\n\n    @staticmethod\n    def sample(logits, temperature, top_k, top_p):\n\n        \"\"\"\n        Adjust logits for sampling based on temperature, top-k, and top-p parameters.\n\n        Args:\n            logits (torch.Tensor): The input logits.\n            temperature (float): The temperature for sampling.\n            top_k (int): The number of top tokens to consider for top-k sampling.\n            top_p (float): The cumulative probability threshold for top-p sampling.\n\n        Returns:\n            torch.Tensor: The adjusted probability distribution.\n        \"\"\"\n\n        if temperature <= 1e-6:\n            return F.one_hot(logits.argmax(dim=-1), num_classes=logits.size(-1)).float()\n\n        logits = logits / temperature\n\n        if top_k > 0:\n            top_k = min(top_k, logits.size(-1))\n            indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n            logits[indices_to_remove] = float('-inf')\n\n        if top_p < 1.0:\n            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n            cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n            sorted_indices_to_remove = cumulative_probs > top_p\n            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n            sorted_indices_to_remove[..., 0] = 0\n            indices_to_remove = sorted_indices_to_remove.scatter(dim=-1, index=sorted_indices, src=sorted_indices_to_remove)\n            logits[indices_to_remove] = float('-inf')\n\n        return F.softmax(logits, dim=-1)\n\n    def generate(self, prompt, temperature=1.0, top_k=0, top_p=1.0, gamma=8, max_new_tokens=50):\n        \"\"\"\n        Generate text using speculative decoding.\n\n        Args:\n            prompt (str): The input prompt to start generation from.\n            temperature (float): The temperature for sampling. Defaults to 1.0.\n            top_k (int): The number of top tokens to consider for top-k sampling. Defaults to 0 (disabled).\n            top_p (float): The cumulative probability threshold for top-p sampling. Defaults to 1.0 (disabled).\n            gamma (int): The number of tokens to generate speculatively in each iteration. Defaults to 5.\n            max_new_tokens (int): The maximum number of new tokens to generate. Defaults to 100.\n\n        Returns:\n            str: The generated text.\n        \"\"\"\n        stime = time.time()\n        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.device)\n        attention_mask = torch.ones_like(input_ids)\n\n        self.no_accepted_tokens = 0\n        betas = []\n        all_gammas = []\n\n        for _ in range(0, max_new_tokens, gamma + 1):\n            # Generate draft outputs\n            all_gammas.append(gamma)\n            start_time = time.time()\n\n            with torch.no_grad():\n                draft_outputs = self.Mq.generate(\n                    input_ids,\n                    attention_mask=attention_mask,\n                    max_new_tokens=gamma,\n                    do_sample=True,\n                    temperature=temperature,\n                    top_k=top_k,\n                    top_p=top_p,\n                    return_dict_in_generate=True,\n                    output_scores=True,\n                    pad_token_id=self.tokenizer.pad_token_id,\n                )\n\n            end_time = time.time()\n\n            draft_tokens = draft_outputs.sequences[:, input_ids.size(1):] #torch.Size([1, 5])\n            draft_probs = torch.stack(draft_outputs.scores).softmax(-1) #torch.Size([5, 1, 50257]) for GPT2\n            #####################\n            #Debugging\n            # Print draft model tokens and decoded words\n#             print(f\"Draft Model: {(end_time-start_time):.3f}s\", end = \" \")\n#             for i, token in enumerate(draft_tokens[0]):\n#                 word = self.tokenizer.decode(token.item(), skip_special_tokens=True)\n#                 print(f\"{word}\", end = \" \")\n            #####################\n\n            # Target model single forward pass\n            start_time = time.time()\n            with torch.no_grad():\n                target_outputs = self.Mp(\n                    torch.cat([input_ids, draft_tokens], dim=1),\n                    attention_mask=torch.cat([attention_mask, torch.ones_like(draft_tokens)], dim=1),\n                    return_dict=True,\n                )\n\n            end_time = time.time()\n#             print(f\"\\n one run of target model: {end_time-start_time:.3f} s\")\n\n            target_logits = target_outputs.logits[:, input_ids.size(1)-1:-1]\n            target_probs = self.sample(target_logits, temperature, top_k, top_p)\n\n            # Speculative sampling\n            accepted_tokens = []\n            for i in range(min(gamma, draft_tokens.size(1))):\n                draft_token = draft_tokens[:, i]\n                draft_prob = draft_probs[i].gather(-1, draft_token.unsqueeze(-1)).squeeze(-1)\n                target_prob = target_probs[:, i].gather(-1, draft_token.unsqueeze(-1)).squeeze(-1)\n\n                accept_prob = torch.min(torch.ones_like(target_prob), target_prob / draft_prob)\n                if torch.rand(1, device=self.device) < accept_prob:\n                    accepted_tokens.append(draft_token)\n                else:\n                    break\n                # if draft_prob <= target_prob:\n                #     # Accept deterministically if draft prob <= target_prob\n                #     accepted_tokens.append(draft_token)\n                # else:\n                #     # Probabilistic rejection if draft prob > target_prob\n                #     rejection_prob = 1 - target_prob / draft_prob\n                #     if torch.rand(1, device=self.device) < rejection_prob:\n                #         break\n            # Print accepted tokens\n            self.no_accepted_tokens += len(accepted_tokens) + 1\n            betas.append(len(accepted_tokens) / gamma)\n\n            #####################\n            #Debugging\n#             print(\"\\nAccepted:\", end = \" \")\n#             for token in accepted_tokens:\n#                 word = self.tokenizer.decode(token.item(), skip_special_tokens=True)\n#                 print(f\"{word}\", end = \" \")\n            #####################\n\n            num_accepted = len(accepted_tokens)\n            acceptance_rate = num_accepted / gamma\n\n            if acceptance_rate > 0.8 and gamma < 10:\n                gamma += 1\n            elif acceptance_rate < 0.2 and gamma > 2:\n                gamma -= 1\n\n\n\n            if num_accepted < draft_probs.size(1):\n                adjusted_probs = torch.clamp(target_probs[:, num_accepted] - draft_probs[num_accepted], min=0)\n                adjusted_probs /= adjusted_probs.sum(dim=-1, keepdim=True)\n                next_token = torch.multinomial(adjusted_probs, num_samples=1)\n            else:\n                next_token = torch.multinomial(target_probs[:, -1], num_samples=1)\n\n            #####################\n            #Debugging\n#             print(f\"\\nTarget Model:\", end = \" \")\n#             print(f\" {self.tokenizer.decode(next_token.item(), skip_special_tokens=True)}\\n\")\n#             print(\"-------------------------------\")\n            ###################\n\n            accepted_tokens.append(next_token)\n            new_tokens = torch.cat([token.view(1, 1) for token in accepted_tokens], dim=1)\n\n            input_ids = torch.cat([input_ids, new_tokens], dim=1)\n            attention_mask = torch.cat([attention_mask, torch.ones_like(new_tokens)], dim=1) #update for next generation\n\n            if input_ids.size(1) - len(self.tokenizer.encode(prompt)) >= max_new_tokens:\n                break\n#         print(f\"\\ntotal time taken: {time.time() -stime:.2f} s\")\n#         print(f\"no of tokens produced {self.no_accepted_tokens}\")\n\n#         Here run Mp for producing self.no_accepted_tokens and note time\n#         total_target_run_time = 0\n#         for token in range(self.no_accepted_tokens):\n#             start_time = time.time()\n#             _ = self.Mp(input_ids)\n#             end_time = time.time()\n#             total_target_run_time += (end_time - start_time)\n\n        self.alpha = sum(betas) / len(betas)\n\n#         print(f\"Total time taken for target model: {total_target_run_time} s\")\n#         print(f\"α = success probability = E(β) = {sum(betas) / len(betas)}\")\n\n        # here run Mp for producing no_accepted_tokens and note time\n        self.total_time_taken = time.time() - stime;\n\n        return self.tokenizer.decode(input_ids[0], skip_special_tokens=True), all_gammas\n\n    def target_generate_greedy(self, prompt, max_new_tokens=50):\n        \"\"\"\n        Generate text using standard greedy decoding with the target model.\n\n        Args:\n            prompt (str): The input prompt to start generation from.\n            max_new_tokens (int): The maximum number of new tokens to generate. Defaults to 50.\n\n        Returns:\n            str: The generated text.\n        \"\"\"\n        model_inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n        greedy_output = self.target_model.generate(**model_inputs, max_new_tokens=max_new_tokens)\n        return self.tokenizer.decode(greedy_output[0])\n\n    def draft_generate_greedy(self, prompt, max_new_tokens=50):\n        \"\"\"\n        Generate text using standard greedy decoding with the draft model.\n\n        Args:\n            prompt (str): The input prompt to start generation from.\n            max_new_tokens (int): The maximum number of new tokens to generate. Defaults to 50\n\n        Returns:\n            str: The generated text.\n        \"\"\"\n\n        model_inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n        greedy_output = self.draft_model.generate(**model_inputs, max_new_tokens=max_new_tokens)\n        return self.tokenizer.decode(greedy_output[0])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-20T21:22:53.825673Z","iopub.execute_input":"2024-11-20T21:22:53.826151Z","iopub.status.idle":"2024-11-20T21:22:53.852069Z","shell.execute_reply.started":"2024-11-20T21:22:53.826119Z","shell.execute_reply":"2024-11-20T21:22:53.851117Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"| Model        | Parameters |\n|--------------|----------------|\n| gpt2-large   | 812 M           |\n| gpt2-medium  | 380 M           |\n| gpt2         | 137 M           |\n| distilgpt2   | 88.2 M          |\n","metadata":{}},{"cell_type":"code","source":"model = SpeculativeDecoder(target_model_name='gpt2-large',\n                                  draft_model_name='distilgpt2',\n                                  device='cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-11-20T21:23:00.079211Z","iopub.execute_input":"2024-11-20T21:23:00.080038Z","iopub.status.idle":"2024-11-20T21:23:26.936228Z","shell.execute_reply.started":"2024-11-20T21:23:00.080005Z","shell.execute_reply":"2024-11-20T21:23:26.935454Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d307e04665c44bc6ac631e45a82205ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9629bb72bca948e69931b606bf131baf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"565f94b3200b492e94de6cc4cade1c8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7e216e97819483e9810afe8eea0b136"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7122737c6d14f36884be15248f126c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dbcbe7fabdf4f6da31806548578bcde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f73fd9cd6e984ece94a0a57d44f9dd90"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"import time\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.ndimage import gaussian_filter1d  # For smoothing\n\ndef evaluate_speculative_decoding(dataset, spec_decoder, max_new_tokens=100, temperature=1.0, top_k=0, top_p=1.0, gamma=3, output_file=\"evaluation_results.txt\"):\n    total_time = 0\n    total_target_model_time = 0\n    total_tokens_produced = 0\n    alphas = []\n\n    # Open file to write outputs\n    with open(output_file, \"w\") as f:\n        # Loop through each sample in the dataset\n        all_gamma_values = []\n        for i, sample in enumerate(tqdm(dataset, desc=\"Evaluating Speculative Decoding\")):\n            prompt = sample['input_text']  # Modify prompt as needed\n\n            # Perform speculative decoding and measure time and alpha\n            start_time = time.time()\n            \n            generated_text, all_gammas = spec_decoder.generate(prompt, temperature=temperature, top_k=top_k, top_p=top_p, gamma=gamma, max_new_tokens=max_new_tokens)\n            # f.write(f\"Generated Text for Sample {i}:\\n{generated_text}\\n\\n\")\n            decoding_time = time.time() - start_time\n\n            # Collect timing metrics and alpha (success probability)\n            total_time += decoding_time / spec_decoder.no_accepted_tokens\n            total_tokens_produced += spec_decoder.no_accepted_tokens  # Assuming no_accepted_tokens is updated in spec_decoder\n            alphas.append(spec_decoder.alpha)  # Assuming `alpha` is updated in `SpeculativeDecoder` after each generation\n            all_gamma_values.extend(all_gammas)\n#         avg_alpha = np.mean(alphas)\n    \n    temp = total_time / len(dataset)\n    avg_alpha = np.mean(alphas)\n    print(\"avg time taken by speculative decoding: \", temp)\n#     print(f\"\\nEvaluation Results on Test Dataset:\")\n#     print(f\"Average time per sample: {avg_time_per_sample:.2f} seconds\")\n    print(f\"Average alpha (acceptance probability): {avg_alpha:.2f}\")\n#     print(f\"Average time per token: {total_time / total_tokens_produced:.4f} seconds\")\n    \n\n    # Smoothing gamma values for a cleaner plot\n    smoothed_gamma_values = gaussian_filter1d(all_gamma_values, sigma=2)  # Adjust sigma for more/less smoothing\n\n    # Plot gamma values\n    plt.figure(figsize=(12, 6))\n    plt.plot(smoothed_gamma_values, label=\"Smoothed Gamma Value\", color='blue', linewidth=2)\n    plt.scatter(range(len(all_gamma_values)), all_gamma_values, s=10, color='red', alpha=0.6, label=\"Original Gamma Values\")\n    plt.axhline(np.mean(all_gamma_values), color='green', linestyle='--', linewidth=1, label=\"Mean Gamma Value\")\n    plt.grid(alpha=0.3)\n    plt.xlabel(\"Generation Step\", fontsize=12)\n    plt.ylabel(\"Gamma\", fontsize=12)\n    plt.title(\"Change in Gamma Value Over Generation Steps\", fontsize=14)\n    plt.legend(fontsize=10)\n    plt.tight_layout()\n    plt.show()\n\n    return {\n#         \"avg_time_per_sample\": avg_time_per_sample,\n#         \"avg_tokens_per_sample\": avg_tokens_per_sample,\n        \"avg_alpha\": avg_alpha,\n    }","metadata":{"execution":{"iopub.status.busy":"2024-11-20T21:23:26.938406Z","iopub.execute_input":"2024-11-20T21:23:26.939082Z","iopub.status.idle":"2024-11-20T21:23:26.949353Z","shell.execute_reply.started":"2024-11-20T21:23:26.939041Z","shell.execute_reply":"2024-11-20T21:23:26.948470Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# test_dataset[1]","metadata":{"execution":{"iopub.status.busy":"2024-11-20T21:23:26.950499Z","iopub.execute_input":"2024-11-20T21:23:26.950857Z","iopub.status.idle":"2024-11-20T21:23:27.279160Z","shell.execute_reply.started":"2024-11-20T21:23:26.950820Z","shell.execute_reply":"2024-11-20T21:23:27.278343Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Run evaluation\nresults = evaluate_speculative_decoding(test_dataset, model)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T21:23:27.281160Z","iopub.execute_input":"2024-11-20T21:23:27.281543Z","iopub.status.idle":"2024-11-20T21:23:41.714594Z","shell.execute_reply.started":"2024-11-20T21:23:27.281505Z","shell.execute_reply":"2024-11-20T21:23:41.713811Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Evaluating Speculative Decoding: 100%|██████████| 10/10 [00:14<00:00,  1.40s/it]\n","output_type":"stream"},{"name":"stdout","text":"avg time taken by speculative decoding:  0.028881561414585543\nAverage alpha (acceptance probability): 0.37\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.ndimage import gaussian_filter1d  # For smoothing\n\ndef evaluate_speculative_decoding(dataset, spec_decoder, max_new_tokens=100, temperature=1.0, top_k=0, top_p=1.0, gamma=3):\n    total_time = 0\n    total_tokens_produced = 0\n    alphas = []\n    all_gamma_values = []  # Store gamma values across all samples\n\n    # Loop through each sample in the dataset\n    for i, sample in enumerate(tqdm(dataset, desc=\"Evaluating Speculative Decoding\")):\n        prompt = sample['input_text']  # Modify prompt as needed\n\n        # Perform speculative decoding and measure time and alpha\n        start_time = time.time()\n        generated_text, gamma_values = spec_decoder.generate(prompt, temperature=temperature, top_k=top_k, top_p=top_p, initial_gamma=gamma, max_new_tokens=max_new_tokens)\n        decoding_time = time.time() - start_time\n\n        total_time += decoding_time\n        total_time = total_time / spec_decoder.no_accepted_tokens\n#         total_tokens_produced += spec_decoder.no_accepted_tokens\n        alphas.append(spec_decoder.alpha)\n        all_gamma_values.extend(gamma_values)  # Collect gamma values for plotting\n\n    # Calculate overall metrics\n#     avg_time_per_sample = total_time / len(dataset)\n#     avg_tokens_per_sample = total_tokens_produced / len(dataset)\n    avg_alpha = np.mean(alphas)\n    \n    temp = total_time / len(dataset)\n    print(\"avg time taken by speculative decoding: \", temp)\n#     print(f\"\\nEvaluation Results on Test Dataset:\")\n#     print(f\"Average time per sample: {avg_time_per_sample:.2f} seconds\")\n    print(f\"Average alpha (acceptance probability): {avg_alpha:.2f}\")\n#     print(f\"Average time per token: {total_time / total_tokens_produced:.4f} seconds\")\n    \n\n    # Smoothing gamma values for a cleaner plot\n    smoothed_gamma_values = gaussian_filter1d(all_gamma_values, sigma=2)  # Adjust sigma for more/less smoothing\n\n    # Plot gamma values\n    plt.figure(figsize=(12, 6))\n    plt.plot(smoothed_gamma_values, label=\"Smoothed Gamma Value\", color='blue', linewidth=2)\n    plt.scatter(range(len(all_gamma_values)), all_gamma_values, s=10, color='red', alpha=0.6, label=\"Original Gamma Values\")\n    plt.axhline(np.mean(all_gamma_values), color='green', linestyle='--', linewidth=1, label=\"Mean Gamma Value\")\n    plt.grid(alpha=0.3)\n    plt.xlabel(\"Generation Step\", fontsize=12)\n    plt.ylabel(\"Gamma\", fontsize=12)\n    plt.title(\"Change in Gamma Value Over Generation Steps\", fontsize=14)\n    plt.legend(fontsize=10)\n    plt.tight_layout()\n    plt.show()\n\n    return {\n        \"avg_time_per_sample\": avg_time_per_sample,\n        \"avg_tokens_per_sample\": avg_tokens_per_sample,\n        \"avg_alpha\": avg_alpha,\n    }","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2024-11-13T13:10:47.968701Z","iopub.execute_input":"2024-11-13T13:10:47.969562Z","iopub.status.idle":"2024-11-13T13:10:47.973343Z","shell.execute_reply.started":"2024-11-13T13:10:47.969521Z","shell.execute_reply":"2024-11-13T13:10:47.972447Z"},"trusted":true},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# model = SpeculativeDecoder(\"gpt2\", \"/kaggle/working/model_output\")  ","metadata":{"execution":{"iopub.status.busy":"2024-11-13T13:11:08.772763Z","iopub.execute_input":"2024-11-13T13:11:08.773620Z","iopub.status.idle":"2024-11-13T13:11:08.777566Z","shell.execute_reply.started":"2024-11-13T13:11:08.773579Z","shell.execute_reply":"2024-11-13T13:11:08.776602Z"},"trusted":true},"outputs":[],"execution_count":32},{"cell_type":"code","source":"op = model.generate(prompt = \"summarize: Ever noticed how plane seats appear to be getting smaller and smaller?\")","metadata":{"execution":{"iopub.status.busy":"2024-11-13T12:30:05.742024Z","iopub.execute_input":"2024-11-13T12:30:05.742670Z","iopub.status.idle":"2024-11-13T12:30:07.530287Z","shell.execute_reply.started":"2024-11-13T12:30:05.742629Z","shell.execute_reply":"2024-11-13T12:30:07.529211Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"op","metadata":{"execution":{"iopub.status.busy":"2024-11-13T12:30:09.753475Z","iopub.execute_input":"2024-11-13T12:30:09.754126Z","iopub.status.idle":"2024-11-13T12:30:09.760103Z","shell.execute_reply.started":"2024-11-13T12:30:09.754084Z","shell.execute_reply":"2024-11-13T12:30:09.758934Z"},"trusted":true},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"\"summarize: Ever noticed how plane seats appear to be getting smaller and smaller? Well wonder no more. MansionMad is having some last minute tweaks to the FedEx box for same.\\n\\nAlso Also:\\n\\nWe asked somebody what they plan like operating this Thanksgiving holiday in their house. Here's what\""},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset\nimport argparse\nfrom datasets import load_dataset\nfrom transformers import GPT2Tokenizer\n\n# Set random seed for reproducibility\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2024-11-20T21:10:43.892858Z","iopub.execute_input":"2024-11-20T21:10:43.893375Z","iopub.status.idle":"2024-11-20T21:10:43.901640Z","shell.execute_reply.started":"2024-11-20T21:10:43.893328Z","shell.execute_reply":"2024-11-20T21:10:43.900493Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CNNDailyMailGPT2Dataset(Dataset):\n    def __init__(self, data, max_length, prompt_prefix=\"summarize: \"):\n        self.prompt_prefix = prompt_prefix\n        self.data = data\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        article = self.data[idx]['article']\n        highlights = self.data[idx]['highlights']\n        input_text = self.prompt_prefix + article\n        input_text = input_text[:max_length]\n        target_text = highlights\n\n        return {\n            'input_text': input_text,\n            'target_text': target_text,\n        }","metadata":{"execution":{"iopub.status.busy":"2024-11-20T21:10:44.380451Z","iopub.execute_input":"2024-11-20T21:10:44.381446Z","iopub.status.idle":"2024-11-20T21:10:47.721001Z","shell.execute_reply.started":"2024-11-20T21:10:44.381394Z","shell.execute_reply":"2024-11-20T21:10:47.720004Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"seed = 42\nmax_length = 128\nset_seed(seed)\ndataset = load_dataset('cnn_dailymail', '3.0.0')\n\nval_data = dataset['validation']\ntest_data = dataset['test']\nval_data = val_data.select(range(3000))\ntest_data = test_data.select(range(10))\n\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ntokenizer.pad_token = tokenizer.eos_token\n\nval_dataset = CNNDailyMailGPT2Dataset(val_data, max_length)\ntest_dataset = CNNDailyMailGPT2Dataset(test_data, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T21:10:47.722600Z","iopub.execute_input":"2024-11-20T21:10:47.722961Z","iopub.status.idle":"2024-11-20T21:11:00.260927Z","shell.execute_reply.started":"2024-11-20T21:10:47.722924Z","shell.execute_reply":"2024-11-20T21:11:00.259911Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/15.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"548863b2f8ec486e8173fbadcd5ee545"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80b97b0df42b417ea85fc97a118d4e35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdea690b650c4122a164a503a1592305"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00002-of-00003.parquet:   0%|          | 0.00/259M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21329afb57a3448c839b37b3f2954be0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/34.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d31c763f1824cf080232d6e1f57130f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/30.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed98a4b2f93549caba01a41812d599b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7197f1893e34f75ac77e35c82c41be9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"202689c256064a5ebf4bd75e97b4f7a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01d857ffa1e441bc8c6d93f8526742ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64d932a02419478f9ba69e2113755067"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e364e92fb6746e78ee91d0c387941b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46f5af2a9f1a4cb99cba6319404f7741"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2be39ab0a4ff4dfa9def1cce657bb9a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e7fb62c380d416fbb09873aa7fe0682"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"len(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T20:14:49.369506Z","iopub.execute_input":"2024-11-20T20:14:49.370310Z","iopub.status.idle":"2024-11-20T20:14:49.375676Z","shell.execute_reply.started":"2024-11-20T20:14:49.370262Z","shell.execute_reply":"2024-11-20T20:14:49.374819Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"50"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"Experts question if packed out planes are putting passengers at risk . U.S consumer advisory group","metadata":{}},{"cell_type":"markdown","source":"## 3 Models ","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nimport time\n\nclass SpeculativeDecoderTriple:\n    def __init__(self, target_model_name, draft_model_name, subdraft_model_name, device='cuda' if torch.cuda.is_available() else 'cpu'):\n        self.device = device\n        self.target_model = AutoModelForCausalLM.from_pretrained(target_model_name).to(self.device)\n        self.draft_model = AutoModelForCausalLM.from_pretrained(draft_model_name).to(self.device)\n        self.subdraft_model = AutoModelForCausalLM.from_pretrained(subdraft_model_name).to(self.device)\n        self.tokenizer = AutoTokenizer.from_pretrained(target_model_name)\n\n        if self.tokenizer.pad_token is None:\n            self.tokenizer.pad_token = self.tokenizer.eos_token\n            \n        self.no_accepted_tokens = 0\n        self.alpha_draft = 0\n        self.alpha_target = 0 \n\n        self.target_model.eval()\n        self.draft_model.eval()\n        self.subdraft_model.eval()\n\n    @staticmethod\n    def sample(logits, temperature=1.0, top_k=0, top_p=1.0):\n        if temperature <= 1e-6:\n            return F.one_hot(logits.argmax(dim=-1), num_classes=logits.size(-1)).float()\n        \n        logits = logits / temperature\n        if top_k > 0:\n            top_k = min(top_k, logits.size(-1))\n            indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n            logits[indices_to_remove] = float('-inf')\n\n        if top_p < 1.0:\n            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n            cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n            sorted_indices_to_remove = cumulative_probs > top_p\n            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n            sorted_indices_to_remove[..., 0] = 0\n            indices_to_remove = sorted_indices_to_remove.scatter(dim=-1, index=sorted_indices, src=sorted_indices_to_remove)\n            logits[indices_to_remove] = float('-inf')\n\n        return F.softmax(logits, dim=-1)\n\n    def generate(self, prompt, temperature=1.0, top_k=0, top_p=1.0, gamma=4, max_new_tokens=100):\n        stime = time.time()\n        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.device)\n        attention_mask = torch.ones_like(input_ids)\n        no_accepted_tokens = 0\n        betas_draft = []\n        betas_target = []\n        self.no_accepted_tokens = 0\n\n        for _ in range(0, max_new_tokens, gamma + 1):\n            with torch.no_grad():\n                # Step 1: Generate draft from subdraft_model (distilgpt2)\n                subdraft_outputs = self.subdraft_model.generate(\n                    input_ids, attention_mask=attention_mask, max_new_tokens=gamma,\n                    do_sample=True, temperature=temperature, top_k=top_k, top_p=top_p,\n                    return_dict_in_generate=True, output_scores=True,\n                    pad_token_id=self.tokenizer.pad_token_id,\n                )\n                \n                subdraft_tokens = subdraft_outputs.sequences[:, input_ids.size(1):]\n                subdraft_probs = torch.stack(subdraft_outputs.scores).softmax(-1)\n                print(\"---------------------------\")\n                print(\"Subdraft model:\", end = \" \")\n                for i, token in enumerate(subdraft_tokens[0]):\n                    word = self.tokenizer.decode(token.item(), skip_special_tokens=True)\n                    print(f\"{word}\", end=\" \")\n                print()\n                print(\"---------------------------\")\n                print()\n\n                # Step 2: Use subdraft tokens to inform draft_model (gpt2)\n                draft_outputs = self.draft_model(\n                    torch.cat([input_ids, subdraft_tokens], dim=1),\n                    attention_mask=torch.cat([attention_mask, torch.ones_like(subdraft_tokens)], dim=1),\n                    return_dict=True,\n                )\n                \n                draft_logits = draft_outputs.logits[:, input_ids.size(1):]\n                draft_probs = self.sample(draft_logits, temperature, top_k, top_p)\n                print(\"Draft model verified!\")\n                print()\n                \n                accepted_tokens_by_draft = []\n                for i in range(min(gamma, subdraft_tokens.size(1))):\n                    subdraft_token = subdraft_tokens[:, i]\n                    subdraft_prob = subdraft_probs[i].gather(-1, subdraft_token.unsqueeze(-1)).squeeze(-1)\n                    draft_prob = draft_probs[:, i].gather(-1, subdraft_token.unsqueeze(-1)).squeeze(-1)\n\n                    accept_prob = torch.min(torch.ones_like(draft_prob), draft_prob / subdraft_prob)\n                    if torch.rand(1, device=self.device) < accept_prob:\n                        accepted_tokens_by_draft.append(subdraft_token)\n                    else:\n                        break\n                \n                \n                ##########\n                # code to accept, reject from draft model\n                ########\n                \n                \n                # Print accepted tokens\n                no_accepted_tokens_by_draft = len(accepted_tokens_by_draft) + 1\n                betas_draft.append(len(no_accepted_tokens_by_draft) / gamma)\n                #########3\n                # beta subdraft-draft = len(accepted_tokens by draft)/gamma\n                ########\n                \n                new_gamma = len(accepted_tokens_by_draft)\n                \n                \n                \n                ############\n                # new gamma = total number of accepted tokens\n                ###########\n                # Step 3: Use subdraft and draft tokens to inform target_model (gpt2-medium)\n                target_inputs = torch.cat([input_ids, accepted_tokens_by_draft], dim=1)\n                target_attention_mask = torch.cat([attention_mask, torch.ones_like(accepted_tokens_by_draft)], dim=1)\n\n                target_outputs = self.target_model(\n                    target_inputs,\n                    attention_mask=target_attention_mask,\n                    return_dict=True,\n                )\n\n                target_logits = target_outputs.logits[:, input_ids.size(1) - 1:-1]\n                target_probs = self.sample(target_logits, temperature, top_k, top_p)\n                print(\"Target model verified!\")\n                print()\n\n                # Speculative sampling process\n                # Inside generate() method, adjust the loop to handle fewer subdraft tokens\n                \n                #accepted_tokens by target\n                accepted_tokens = []\n                num_subdraft_tokens = subdraft_tokens.size(1)\n\n                # Ensure the loop only iterates up to the number of tokens available\n                print(f\"Accepted token:\", end = \" \")\n                for i in range(min(gamma, num_subdraft_tokens)):\n                    draft_token = subdraft_tokens[:, i]\n                    subdraft_prob = subdraft_probs[i].gather(-1, draft_token.unsqueeze(-1)).squeeze(-1)\n                    draft_prob = draft_probs[:, i].gather(-1, draft_token.unsqueeze(-1)).squeeze(-1)\n                    target_prob = target_probs[:, i].gather(-1, draft_token.unsqueeze(-1)).squeeze(-1)\n\n                    accept_prob = torch.min(torch.ones_like(target_prob), target_prob / draft_prob)\n                    if torch.rand(1, device=self.device) < accept_prob:\n                        accepted_tokens.append(draft_token)\n                        word = self.tokenizer.decode(draft_token.item(), skip_special_tokens=True)\n                        print(f\"{word}\", end=\" \")\n                    else:\n                        break\n\n                print()\n                \n                \n                self.no_accepted_tokens = len(accepted_tokens)\n                #######\n                # betas - draft-target\n                #########\n                betas.append(len(accepted_tokens)/gamma)\n\n                # Append next token if draft predictions are exhausted\n                if num_accepted < gamma:\n                    adjusted_probs = torch.clamp(target_probs[:, num_accepted] - draft_probs[num_accepted], min=0)\n                    adjusted_probs /= adjusted_probs.sum(dim=-1, keepdim=True)\n                    next_token = torch.multinomial(adjusted_probs, num_samples=1)\n                else:\n                    next_token = torch.multinomial(target_probs[:, -1], num_samples=1)\n\n                #####################\n                #Debugging\n    #             print(f\"\\nTarget Model:\", end = \" \")\n    #             print(f\" {self.tokenizer.decode(next_token.item(), skip_special_tokens=True)}\\n\")\n    #             print(\"-------------------------------\")\n                ###################\n\n                accepted_tokens.append(next_token)\n                new_tokens = torch.cat([token.view(1, 1) for token in accepted_tokens], dim=1)\n\n                input_ids = torch.cat([input_ids, new_tokens], dim=1)\n                attention_mask = torch.cat([attention_mask, torch.ones_like(new_tokens)], dim=1) #update for next generation\n\n                if input_ids.size(1) - len(self.tokenizer.encode(prompt)) >= max_new_tokens:\n                    break\n\n        print(f\"Total time taken: {time.time() - stime:.2f} s\")\n        \n        # alpha subdraft-draft = sum(beta-subdraft) / len(beta-subdraft)\n        \n        \n        \n        # alpha draft-target = sum(betas-draft) / len(betas-draft)\n        self.alpha_draft = sum(betas_draft) / len(betas_draft)\n        self.alpha_target = sum(betas_target) / len(betas_target)\n        return self.tokenizer.decode(input_ids[0], skip_special_tokens=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-19T19:04:35.030766Z","iopub.execute_input":"2024-11-19T19:04:35.031130Z","iopub.status.idle":"2024-11-19T19:04:35.415294Z","shell.execute_reply.started":"2024-11-19T19:04:35.031082Z","shell.execute_reply":"2024-11-19T19:04:35.414225Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Initialize the multi-level speculative decoder\nspec_decoder = SpeculativeDecoderTriple(\n    target_model_name=\"gpt2-medium\",\n    draft_model_name=\"gpt2\",\n    subdraft_model_name=\"distilgpt2\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T18:38:44.114217Z","iopub.status.idle":"2024-11-19T18:38:44.114665Z","shell.execute_reply.started":"2024-11-19T18:38:44.114446Z","shell.execute_reply":"2024-11-19T18:38:44.114468Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt = \"I am\"\ntemperature = 0.8\ntop_k = 50\ntop_p = 0.95\ngamma = 5\nmax_new_tokens = 100\n\n# Run the speculative decoding generation\noutput_text = spec_decoder.generate(\n    prompt=prompt,\n    temperature=temperature,\n    top_k=top_k,\n    top_p=top_p,\n    gamma=gamma,\n    max_new_tokens=max_new_tokens\n)\n\n# Print the generated text\nprint(\"Generated Text:\\n\", output_text)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T18:38:44.115756Z","iopub.status.idle":"2024-11-19T18:38:44.116185Z","shell.execute_reply.started":"2024-11-19T18:38:44.115966Z","shell.execute_reply":"2024-11-19T18:38:44.115987Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Debuging","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nimport time\n\nclass SpeculativeDecoderTriple:\n    def __init__(self, target_model_name, draft_model_name, subdraft_model_name, device='cuda' if torch.cuda.is_available() else 'cpu'):\n        self.device = device\n        self.target_model = AutoModelForCausalLM.from_pretrained(target_model_name).to(self.device)\n        self.draft_model = AutoModelForCausalLM.from_pretrained(draft_model_name).to(self.device)\n        self.subdraft_model = AutoModelForCausalLM.from_pretrained(subdraft_model_name).to(self.device)\n        self.tokenizer = AutoTokenizer.from_pretrained(target_model_name)\n\n        if self.tokenizer.pad_token is None:\n            self.tokenizer.pad_token = self.tokenizer.eos_token\n            \n        self.no_accepted_tokens = 0\n        self.alpha = 0 \n\n        self.target_model.eval()\n        self.draft_model.eval()\n        self.subdraft_model.eval()\n\n    @staticmethod\n    def sample(logits, temperature=1.0, top_k=0, top_p=1.0):\n        if temperature <= 1e-6:\n            return F.one_hot(logits.argmax(dim=-1), num_classes=logits.size(-1)).float()\n        \n        logits = logits / temperature\n        if top_k > 0:\n            top_k = min(top_k, logits.size(-1))\n            indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n            logits[indices_to_remove] = float('-inf')\n\n        if top_p < 1.0:\n            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n            cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n            sorted_indices_to_remove = cumulative_probs > top_p\n            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n            sorted_indices_to_remove[..., 0] = 0\n            indices_to_remove = sorted_indices_to_remove.scatter(dim=-1, index=sorted_indices, src=sorted_indices_to_remove)\n            logits[indices_to_remove] = float('-inf')\n\n        return F.softmax(logits, dim=-1)\n\n    def generate(self, prompt, temperature=1.0, top_k=0, top_p=1.0, gamma=4, max_new_tokens=100):\n        stime = time.time()\n        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.device)\n        attention_mask = torch.ones_like(input_ids)\n        betas_draft = []\n        betas_target = []\n\n        for _ in range(0, max_new_tokens, gamma + 1):\n            with torch.no_grad():\n                # Step 1: Generate subdraft tokens\n                ####################\n                subdraft_outputs = self.subdraft_model.generate(\n                    input_ids, attention_mask=attention_mask, max_new_tokens=gamma,\n                    do_sample=True, temperature=temperature, top_k=top_k, top_p=top_p,\n                    return_dict_in_generate=True, output_scores=True,\n                    pad_token_id=self.tokenizer.pad_token_id,\n                )\n\n                subdraft_tokens = subdraft_outputs.sequences[:, input_ids.size(1):]\n                subdraft_probs = torch.stack(subdraft_outputs.scores).softmax(-1)\n#                 print(subdraft_tokens.shape)\n#                 print(subdraft_probs.shape)\n#                 print(\"---------------------------\")\n#                 print(\"Subdraft model:\", end = \" \")\n#                 for i, token in enumerate(subdraft_tokens[0]):\n#                     word = self.tokenizer.decode(token.item(), skip_special_tokens=True)\n#                     print(f\"{word}\", end=\" \")\n#                 print()\n#                 print(\"---------------------------\")\n#                 print()\n                \n                \n                \n                # Step 2: Validate subdraft tokens with draft model\n                draft_outputs = self.draft_model(\n                    torch.cat([input_ids, subdraft_tokens], dim=1),\n                    attention_mask=torch.cat([attention_mask, torch.ones_like(subdraft_tokens)], dim=1),\n                    return_dict=True,\n                )\n                draft_logits = draft_outputs.logits[:, input_ids.size(1)-1:-1]\n                draft_probs = self.sample(draft_logits, temperature, top_k, top_p)\n                \n#                 print(\"draft_logits\", draft_logits.shape)\n#                 print(\"draft_probs\", draft_probs.shape)\n                ###############\n                #accept reject from draft model\n                ##############\n                \n                accepted_tokens_draft = []\n                for i in range(min(gamma, subdraft_tokens.size(1))):\n                    subdraft_token = subdraft_tokens[:, i]\n                    subdraft_prob = subdraft_probs[i].gather(-1, subdraft_token.unsqueeze(-1)).squeeze(-1)\n                    draft_prob = draft_probs[:, i].gather(-1, subdraft_token.unsqueeze(-1)).squeeze(-1)\n                    if subdraft_prob == 0 or draft_prob == 0:\n#                         print(f\"Skipping token at index {i} due to zero probability.\")\n                        continue \n                    accept_prob = torch.min(torch.ones_like(draft_prob), draft_prob / subdraft_prob)\n#                     print(f\"accept_prob at index {i}: {accept_prob}\")\n                    if torch.rand(1, device=self.device) < accept_prob:\n                        accepted_tokens_draft.append(subdraft_token)\n#                         print(f\"Accepted subdraft token at index {i}: {subdraft_token}\")\n                    else:\n#                         print(f\"Rejected subdraft token at index {i}.\")\n                        break\n#                 print(f\"Number of accepted tokens in draft: {len(accepted_tokens_draft)}\")\n                 \n                #####################\n                #Debugging\n#                 print(\"\\nAccepted by draft:\", end = \" \")\n#                 for token in accepted_tokens_draft:\n#                     word = self.tokenizer.decode(token.item(), skip_special_tokens=True)\n#                     print(f\"{word}\", end = \" \")\n#                 print()\n                #####################\n                \n                betas_draft.append(len(accepted_tokens_draft) / gamma)\n                num_accepted_draft = len(accepted_tokens_draft)\n#                 print(\"draft beta: \",betas_draft[-1])\n                \n                if num_accepted_draft < subdraft_probs.size(1):\n                    adjusted_probs = torch.clamp(draft_probs[:, num_accepted_draft] - subdraft_probs[num_accepted_draft], min=0)\n                    adjusted_probs /= adjusted_probs.sum(dim=-1, keepdim=True)\n                    next_token = torch.multinomial(adjusted_probs, num_samples=1)\n                else:\n                    next_token = torch.multinomial(draft_probs[:, -1], num_samples=1)\n                    \n                #####################\n                #Debugging\n#                 print(next_token.shape)\n#                 print(f\"\\Draft Model:\", end = \" \")\n#                 print(f\" {self.tokenizer.decode(next_token.item(), skip_special_tokens=True)}\\n\")\n#                 print(\"-------------------------------\")\n                ###################\n                \n                accepted_tokens_draft.append(next_token)\n                new_tokens_draft = torch.cat([token.view(1, 1) for token in accepted_tokens_draft], dim=1)\n\n                input_ids_target = torch.cat([input_ids, new_tokens_draft], dim=1)\n#                 attention_mask = torch.cat([attention_mask, torch.ones_like(new_tokens_draft)], dim=1) #update for next generation\n                \n#                 accepted_tokens_draft = torch.cat(accepted_tokens_draft, dim=1) if accepted_tokens_draft else None\n                \n#                 print(\"after adding new token: \", accepted_tokens_draft.shape)\n                new_gamma = len(accepted_tokens_draft)\n            \n                \n#                 accepted_tokens_draft_tensor = torch.stack(accepted_tokens_draft).unsqueeze(0)\n\n#                 print(accepted_tokens_draft_tensor.shape)\n                ################\n                # Done...........\n                ################\n                \n                # Step 3: Validate accepted draft tokens with target model\n                # Target Model\n                ##################\n                \n                \n                # Combine accepted tokens into a tensor\n#                 accepted_tokens_draft_tensor = torch.cat(accepted_tokens_draft, dim=1)\n                target_inputs = torch.cat([input_ids_target, new_tokens_draft], dim=1)\n                target_attention_mask = torch.cat([attention_mask, torch.ones_like(new_tokens_draft)], dim=1)\n\n                # Pass to target model\n                target_outputs = self.target_model(\n                    target_inputs,\n                    attention_mask=target_attention_mask,\n                    return_dict=True,\n                )\n                target_logits = target_outputs.logits[:, input_ids.size(1)-1:-1]\n                target_probs = self.sample(target_logits, temperature, top_k, top_p)\n                \n                \n\n                # Validate tokens with target model\n                \n                accepted_tokens_target = []\n                for i in range(new_tokens_draft.size(1)):\n                    draft_token = new_tokens_draft[:, i]\n\n                    # Ensure the dimensions of draft_probs and target_probs are correct\n                    if draft_probs.size(1) <= i or target_probs.size(1) <= i:\n#                         print(f\"Skipping index {i}: draft_probs or target_probs out of bounds.\")\n                        break\n\n                    # Compute probabilities\n                    draft_prob = draft_probs[:, i].gather(-1, draft_token.unsqueeze(-1)).squeeze(-1)\n                    target_prob = target_probs[:, i].gather(-1, draft_token.unsqueeze(-1)).squeeze(-1)\n                    \n                    # Calculate acceptance probability\n                    accept_prob = torch.min(torch.ones_like(target_prob), target_prob / draft_prob)\n\n                    # Accept or reject the token\n                    if torch.rand(1, device=self.device) < accept_prob:\n                        accepted_tokens_target.append(draft_token)\n                    else:\n                        break\n\n                # Debugging output\n#                 print(f\"Accepted tokens in target model: {len(accepted_tokens_target)}\")\n\n#                 print(\"target accepted: \", len(accepted_tokens_target))\n                betas_target.append(len(accepted_tokens_target) / new_gamma)\n#                 print(\"target beta: \", betas_target[-1])\n\n                num_accepted_by_target = len(accepted_tokens_target)\n\n\n                if num_accepted_by_target < target_probs.size(1) and num_accepted_by_target < draft_probs.size(1):\n                    adjusted_probs = torch.clamp(\n                        target_probs[:, num_accepted_by_target] - draft_probs[:, num_accepted_by_target],\n                        min=0\n                    )\n                    adjusted_probs /= adjusted_probs.sum(dim=-1, keepdim=True)\n                    next_token_target = torch.multinomial(adjusted_probs, num_samples=1)\n                else:\n                    next_token_target = torch.multinomial(target_probs[:, -1], num_samples=1)\n\n\n                \n                accepted_tokens_target.append(next_token_target)\n                new_tokens_target = torch.cat([token.view(1, 1) for token in accepted_tokens_target], dim=1)\n\n                input_ids = torch.cat([input_ids, new_tokens_target], dim=1)\n                attention_mask = torch.cat([attention_mask, torch.ones_like(new_tokens_target)], dim=1) #update for next generation\n                #####################\n                #Debugging\n#                 print(f\"\\nTarget Model:\", end = \" \")\n#                 print(f\" {self.tokenizer.decode(next_token_target.item(), skip_special_tokens=True)}\\n\")\n#                 print(\"-------------------------------\")\n                ###################\n                \n#                 if accepted_tokens_target:\n#                     accepted_tokens_target_tensor = torch.cat(accepted_tokens_target, dim=1)\n#                     input_ids = torch.cat([input_ids, accepted_tokens_target_tensor], dim=1)\n#                     attention_mask = torch.cat([attention_mask, torch.ones_like(accepted_tokens_target_tensor)], dim=1)\n\n            if input_ids.size(1) - len(self.tokenizer.encode(prompt)) >= max_new_tokens:\n                break\n\n        self.alpha_draft = sum(betas_draft) / len(betas_draft) if betas_draft else 0\n        self.alpha_target = sum(betas_target) / len(betas_target) if betas_target else 0\n#         print(f\"Total time taken: {time.time() - stime:.2f} s\")\n        return self.tokenizer.decode(input_ids[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T19:28:03.116236Z","iopub.execute_input":"2024-11-20T19:28:03.116567Z","iopub.status.idle":"2024-11-20T19:28:03.202159Z","shell.execute_reply.started":"2024-11-20T19:28:03.116536Z","shell.execute_reply":"2024-11-20T19:28:03.201172Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Initialize the multi-level speculative decoder\nspec_decoder = SpeculativeDecoderTriple(\n    target_model_name=\"gpt2-large\",\n    draft_model_name=\"gpt2\",\n    subdraft_model_name=\"distilgpt2\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T19:28:11.670968Z","iopub.execute_input":"2024-11-20T19:28:11.671328Z","iopub.status.idle":"2024-11-20T19:28:35.893490Z","shell.execute_reply.started":"2024-11-20T19:28:11.671298Z","shell.execute_reply":"2024-11-20T19:28:35.892086Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c73e35e1a08f419c8e1dc34bf2807f6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8a158063b454cd19a03bd8eb710778f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e30d3ea6f7f45439b1597896f100633"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1ce4d4fada14087bbda21f0a7d4e7a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8eaaa12ea81847a79b1c847c6eddc7e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1510b72f05f54285bba3a5517f3de7f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37c9153ddfc94a52bc829dda2f029644"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5bdab7b736942c79aab18f93c1ba8c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7f077bfbe9d4fdea973a4ca5c20e324"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c95a01f50eb47fbb3193f79ac3dcb24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71130f673fc44abab7eff97f7ddf2863"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"606d81688de9490b808e73ff153768e7"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"seed = 42\nmax_length = 128\nset_seed(seed)\ndataset = load_dataset('cnn_dailymail', '3.0.0')\n\nval_data = dataset['validation']\ntest_data = dataset['test']\nval_data = val_data.select(range(3000))\ntest_data = test_data.select(range(50))\n\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ntokenizer.pad_token = tokenizer.eos_token\n\nval_dataset = CNNDailyMailGPT2Dataset(val_data, max_length)\ntest_dataset = CNNDailyMailGPT2Dataset(test_data, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T19:29:00.720118Z","iopub.execute_input":"2024-11-20T19:29:00.720522Z","iopub.status.idle":"2024-11-20T19:29:03.088645Z","shell.execute_reply.started":"2024-11-20T19:29:00.720490Z","shell.execute_reply":"2024-11-20T19:29:03.087844Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import time\nimport numpy as np\nfrom tqdm import tqdm\n\ndef evaluate_speculative_decoding(dataset, spec_decoder, max_new_tokens=100, temperature=1.0, top_k=0, top_p=1.0, gamma=5, output_file=\"evaluation_results.txt\"):\n    total_time = 0\n    total_target_model_time = 0\n    total_tokens_produced = 0\n    alphas_draft = []\n    alphas_target = []\n\n    # Open file to write outputs\n    with open(output_file, \"w\") as f:\n        # Loop through each sample in the dataset\n        temp = 0\n        for i, sample in enumerate(tqdm(dataset, desc=\"Evaluating Speculative Decoding\")):\n            prompt = sample['input_text']  # Modify prompt as needed\n\n            # Perform speculative decoding and measure time and alpha\n            start_time = time.time()\n            generated_text = spec_decoder.generate(prompt, temperature=temperature, top_k=top_k, top_p=top_p, gamma=gamma, max_new_tokens=max_new_tokens)\n            # f.write(f\"Generated Text for Sample {i}:\\n{generated_text}\\n\\n\")\n            temp += len(generated_text.split())\n            decoding_time = time.time() - start_time\n\n            # Collect timing metrics and alpha (success probability)\n            total_time += decoding_time\n            total_tokens_produced += spec_decoder.no_accepted_tokens  # Assuming no_accepted_tokens is updated in spec_decoder\n            alphas_draft.append(spec_decoder.alpha_draft)\n            alphas_target.append(spec_decoder.alpha_target)\n\n        # Calculate overall metrics\n        avg_time_per_sample = total_time / len(dataset)\n        avg_tokens_per_sample = total_tokens_produced / len(dataset)\n        avg_alpha_draft = np.mean(alphas_draft)\n        avg_alpha_target = np.mean(alphas_target)\n        # Write summary metrics to file\n        print(\"\\nEvaluation Results on Test Dataset:\\n\")\n#         print(f\"Average time per sample: {avg_time_per_sample:.2f} seconds\\n\")\n#         print(f\"Average tokens per sample: {avg_tokens_per_sample:.2f}\\n\")\n        print(f\"average token by speculative {total_time / temp}\")\n        print(f\"Average alpha (acceptance probability) Draft: {avg_alpha_draft:.2f}\\n\")\n        print(f\"Average alpha (acceptance probability) Target: {avg_alpha_target:.2f}\\n\")\n\n    return {\n        \"avg_time_per_sample\": avg_time_per_sample,\n        \"avg_tokens_per_sample\": avg_tokens_per_sample,\n    }","metadata":{"execution":{"iopub.status.busy":"2024-11-20T19:37:01.920583Z","iopub.execute_input":"2024-11-20T19:37:01.921433Z","iopub.status.idle":"2024-11-20T19:37:01.929666Z","shell.execute_reply.started":"2024-11-20T19:37:01.921398Z","shell.execute_reply":"2024-11-20T19:37:01.928618Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"evaluate_speculative_decoding(test_dataset, spec_decoder)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T19:37:02.145237Z","iopub.execute_input":"2024-11-20T19:37:02.145881Z","iopub.status.idle":"2024-11-20T19:38:04.329028Z","shell.execute_reply.started":"2024-11-20T19:37:02.145848Z","shell.execute_reply":"2024-11-20T19:38:04.328097Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Evaluating Speculative Decoding: 100%|██████████| 50/50 [01:02<00:00,  1.24s/it]","output_type":"stream"},{"name":"stdout","text":"\nEvaluation Results on Test Dataset:\n\naverage token by speculative 0.025154487185750522\nAverage alpha (acceptance probability) Draft: 0.41\n\nAverage alpha (acceptance probability) Target: 0.48\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'avg_time_per_sample': 1.242128577232361, 'avg_tokens_per_sample': 0.0}"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"prompt = \"I am\"\ntemperature = 0.8\ntop_k = 0\ntop_p = 1\ngamma = 5\nmax_new_tokens = 100\n\n# Run the speculative decoding generation\noutput_text = spec_decoder.generate(\n    prompt=prompt,\n    temperature=temperature,\n    top_k=top_k,\n    top_p=top_p,\n    gamma=gamma,\n    max_new_tokens=max_new_tokens\n)\noutput_text\n# Print the generated text\n# print(\"Generated Text:\\n\", output_text)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T18:25:08.690857Z","iopub.execute_input":"2024-11-20T18:25:08.691497Z","iopub.status.idle":"2024-11-20T18:25:09.679055Z","shell.execute_reply.started":"2024-11-20T18:25:08.691464Z","shell.execute_reply":"2024-11-20T18:25:09.678044Z"},"trusted":true},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'I am unable to comment on this product yet,\" says company spokeswoman Amy ShahWeedoft. \"We are excited to announce that our customers are cheering for us.\"\\n\\nMore than 17,000 online reviews'"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"spec_decoder.alpha_draft, spec_decoder.alpha_target","metadata":{"execution":{"iopub.status.busy":"2024-11-20T16:47:26.277124Z","iopub.execute_input":"2024-11-20T16:47:26.277764Z","iopub.status.idle":"2024-11-20T16:47:26.283338Z","shell.execute_reply.started":"2024-11-20T16:47:26.277728Z","shell.execute_reply":"2024-11-20T16:47:26.282426Z"},"trusted":true},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(0.6352941176470588, 0.40196078431372545)"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"## Recursive code","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nimport time","metadata":{"execution":{"iopub.status.busy":"2024-11-14T17:34:21.726420Z","iopub.execute_input":"2024-11-14T17:34:21.727211Z","iopub.status.idle":"2024-11-14T17:34:21.732557Z","shell.execute_reply.started":"2024-11-14T17:34:21.727170Z","shell.execute_reply":"2024-11-14T17:34:21.731413Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class SpeculativeDecoderRecursive:\n    def __init__(self, model_names, device='cuda' if torch.cuda.is_available() else 'cpu'):\n        self.device = device\n        self.models = [AutoModelForCausalLM.from_pretrained(name).to(self.device) for name in model_names]\n        self.tokenizer = AutoTokenizer.from_pretrained(model_names[-1])\n        self.total_time = 0\n        self.no_accepted_tokens = 0\n        self.alpha = 0\n        if self.tokenizer.pad_token is None:\n            self.tokenizer.pad_token = self.tokenizer.eos_token\n\n        for model in self.models:\n            model.eval()\n\n    @staticmethod\n    def sample(logits, temperature=1.0, top_k=0, top_p=1.0):\n        if temperature <= 1e-6:\n            return F.one_hot(logits.argmax(dim=-1), num_classes=logits.size(-1)).float()\n        \n        logits = logits / temperature\n        if top_k > 0:\n            top_k = min(top_k, logits.size(-1))\n            indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n            logits[indices_to_remove] = float('-inf')\n\n        if top_p < 1.0:\n            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n            cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n            sorted_indices_to_remove = cumulative_probs > top_p\n            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n            sorted_indices_to_remove[..., 0] = 0\n            indices_to_remove = sorted_indices_to_remove.scatter(dim=-1, index=sorted_indices, src=sorted_indices_to_remove)\n            logits[indices_to_remove] = float('-inf')\n\n        return F.softmax(logits, dim=-1)\n\n    def generate(self, prompt, temperature=1.0, top_k=0, top_p=1.0, gamma=4, max_new_tokens=100):\n        self.no_accepted_tokens = 0\n        accepted_token_count = 0\n        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.device)\n        attention_mask = torch.ones_like(input_ids)\n\n        for _ in range(0, max_new_tokens, gamma + 1):\n            with torch.no_grad():\n                # Start recursive speculative generation through draft models\n                accepted_tokens = self.recursive_speculate(input_ids, attention_mask, temperature, top_k, top_p, gamma)\n\n                # Append accepted tokens to input\n                if accepted_tokens:\n                    new_tokens = torch.cat(accepted_tokens, dim=1)\n                    input_ids = torch.cat([input_ids, new_tokens], dim=1)\n                    attention_mask = torch.cat([attention_mask, torch.ones_like(new_tokens)], dim=1)\n                    accepted_token_count += len(accepted_tokens)\n\n                # Check if maximum tokens have been generated\n                if input_ids.size(1) - len(self.tokenizer.encode(prompt)) >= max_new_tokens:\n                    break\n\n        # Track alpha (acceptance probability)\n        self.no_accepted_tokens = accepted_token_count\n        self.alpha = accepted_token_count / max_new_tokens if max_new_tokens else 0\n        return self.tokenizer.decode(input_ids[0], skip_special_tokens=True)\n\n    def recursive_speculate(self, input_ids, attention_mask, temperature, top_k, top_p, gamma, level=0):\n        if level == len(self.models) - 1:\n            target_outputs = self.models[level](\n                input_ids, attention_mask=attention_mask, return_dict=True\n            )\n\n            # Ensure we only access the last set of logits if available\n            if target_outputs.logits.size(1) > 0:\n                target_logits = target_outputs.logits[:, -1, :]\n                return [torch.multinomial(self.sample(target_logits, temperature, top_k, top_p), 1)]\n\n        # Recursive case: Speculate with the current draft model\n        speculative_outputs = self.models[level].generate(\n            input_ids, attention_mask=attention_mask, max_new_tokens=gamma,\n            do_sample=True, temperature=temperature, top_k=top_k, top_p=top_p,\n            return_dict_in_generate=True, output_scores=True,\n            pad_token_id=self.tokenizer.pad_token_id,\n        )\n        speculative_tokens = speculative_outputs.sequences[:, input_ids.size(1):]\n        speculative_probs = torch.stack(speculative_outputs.scores).softmax(-1)\n\n        accepted_tokens = []\n        for i in range(gamma):\n            # Recurse to the next model level\n            next_level_accepted_tokens = self.recursive_speculate(\n                torch.cat([input_ids, speculative_tokens[:, :i+1]], dim=1),\n                torch.cat([attention_mask, torch.ones_like(speculative_tokens[:, :i+1])], dim=1),\n                temperature, top_k, top_p, gamma, level + 1\n            )\n            if next_level_accepted_tokens:\n                accepted_tokens.append(speculative_tokens[:, i:i+1])\n            else:\n                break  # Stop if the token is rejected\n        return accepted_tokens","metadata":{"execution":{"iopub.status.busy":"2024-11-14T17:34:21.907293Z","iopub.execute_input":"2024-11-14T17:34:21.907619Z","iopub.status.idle":"2024-11-14T17:34:26.257597Z","shell.execute_reply.started":"2024-11-14T17:34:21.907580Z","shell.execute_reply":"2024-11-14T17:34:26.256478Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def evaluate_speculative_decoding_recursive(dataset, spec_decoder, max_new_tokens=100, temperature=1.0, top_k=0, top_p=1.0, gamma=4, output_file=\"evaluation_results.txt\"):\n    total_time = 0\n    total_tokens_produced = 0\n    alphas = []\n\n    with open(output_file, \"w\") as f:\n        for i, sample in enumerate(tqdm(dataset, desc=\"Evaluating Speculative Decoding\")):\n            prompt = sample['input_text']\n\n            # Measure time and generate text\n            start_time = time.time()\n            generated_text = spec_decoder.generate(prompt, temperature=temperature, top_k=top_k, top_p=top_p, gamma=gamma, max_new_tokens=max_new_tokens)\n            decoding_time = time.time() - start_time\n\n            # Track metrics\n            total_time += decoding_time\n            total_tokens_produced += spec_decoder.no_accepted_tokens\n            alphas.append(spec_decoder.alpha)\n\n        avg_time_per_sample = total_time / len(dataset)\n        avg_tokens_per_sample = total_tokens_produced / len(dataset)\n        avg_alpha = np.mean(alphas)\n\n        print(\"\\nEvaluation Results:\\n\")\n        print(f\"Average time per sample: {avg_time_per_sample:.2f} seconds\\n\")\n        print(f\"Average tokens per sample: {avg_tokens_per_sample:.2f}\\n\")\n        print(f\"Average alpha (acceptance probability): {avg_alpha:.2f}\\n\")\n\n    return {\n        \"avg_time_per_sample\": avg_time_per_sample,\n        \"avg_tokens_per_sample\": avg_tokens_per_sample,\n        \"avg_alpha\": avg_alpha,\n    }","metadata":{"execution":{"iopub.status.busy":"2024-11-14T17:34:26.259617Z","iopub.execute_input":"2024-11-14T17:34:26.260497Z","iopub.status.idle":"2024-11-14T17:34:26.402353Z","shell.execute_reply.started":"2024-11-14T17:34:26.260461Z","shell.execute_reply":"2024-11-14T17:34:26.401133Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset = load_dataset('cnn_dailymail', '3.0.0')\n\ntest_data = dataset['test']\ntest_data = test_data.select(range(2))\n\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ntokenizer.pad_token = tokenizer.eos_token\n\ntest_dataset = CNNDailyMailGPT2Dataset(test_data, max_length=1024)","metadata":{"execution":{"iopub.status.busy":"2024-11-14T17:34:26.403780Z","iopub.execute_input":"2024-11-14T17:34:26.404124Z","iopub.status.idle":"2024-11-14T17:34:28.033855Z","shell.execute_reply.started":"2024-11-14T17:34:26.404083Z","shell.execute_reply":"2024-11-14T17:34:28.033046Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"model_names = [\"distilgpt2\", \"distilgpt2\", \"distilgpt2\",  \"distilgpt2\", \"gpt2\"]\n\nspec_decoder = SpeculativeDecoderRecursive(model_names=model_names, device='cuda' if torch.cuda.is_available() else 'cpu')\n\nevaluate_speculative_decoding_recursive(test_dataset, spec_decoder)","metadata":{"execution":{"iopub.status.busy":"2024-11-14T17:34:28.035443Z","iopub.execute_input":"2024-11-14T17:34:28.035756Z","iopub.status.idle":"2024-11-14T17:37:46.247818Z","shell.execute_reply.started":"2024-11-14T17:34:28.035724Z","shell.execute_reply":"2024-11-14T17:37:46.246862Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c45a58bc02f943169910130e95e75d44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bf1bd169647443cb890c75537896427"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57ac29c086154831a27bf39067776a9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"148add887e62476fb33ef3dc42d4763b"}},"metadata":{}},{"name":"stderr","text":"Evaluating Speculative Decoding: 100%|██████████| 2/2 [03:09<00:00, 94.90s/it]","output_type":"stream"},{"name":"stdout","text":"\nEvaluation Results:\n\nAverage time per sample: 94.90 seconds\n\nAverage tokens per sample: 80.00\n\nAverage alpha (acceptance probability): 0.80\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'avg_time_per_sample': 94.89699757099152,\n 'avg_tokens_per_sample': 80.0,\n 'avg_alpha': 0.8}"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# Define the prompt and parameters for speculative decoding\nprompt = \"Once upon a time in a land far away\"\ntemperature = 0.7\ntop_k = 50\ntop_p = 0.9\ngamma = 4\nmax_new_tokens = 50\n\n# Run speculative decoding and print the generated text\ngenerated_text = spec_decoder.generate(prompt, temperature=temperature, top_k=top_k, top_p=top_p, gamma=gamma, max_new_tokens=max_new_tokens)\nprint(\"Generated text:\", generated_text)","metadata":{"execution":{"iopub.status.busy":"2024-11-14T17:27:19.505244Z","iopub.status.idle":"2024-11-14T17:27:19.505607Z","shell.execute_reply.started":"2024-11-14T17:27:19.505429Z","shell.execute_reply":"2024-11-14T17:27:19.505448Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"spec_decoder.total_time","metadata":{"execution":{"iopub.status.busy":"2024-11-12T17:02:19.363380Z","iopub.execute_input":"2024-11-12T17:02:19.363673Z","iopub.status.idle":"2024-11-12T17:02:19.370506Z","shell.execute_reply.started":"2024-11-12T17:02:19.363643Z","shell.execute_reply":"2024-11-12T17:02:19.369551Z"},"trusted":true},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"23.077998161315918"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"#### dynamic gamma","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-11-20T20:14:54.144115Z","iopub.execute_input":"2024-11-20T20:14:54.144660Z","iopub.status.idle":"2024-11-20T20:14:54.148873Z","shell.execute_reply.started":"2024-11-20T20:14:54.144622Z","shell.execute_reply":"2024-11-20T20:14:54.147839Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class SpeculativeDecoder:\n    \"\"\"\n    A class implementing speculative decoding for language models.\n\n    This class uses a larger target model and a smaller draft model to perform\n    speculative decoding, potentially speeding up text generation.\n\n    Attributes:\n        device (str): The device to run the models on ('cuda' or 'cpu').\n        target_model (AutoModelForCausalLM): The larger, more accurate language model.\n        draft_model (AutoModelForCausalLM): The smaller, faster language model for draft predictions.\n        tokenizer (AutoTokenizer): The tokenizer for both models.\n    \"\"\"\n    \n\n    def __init__(self, target_model_name, draft_model_name, device='cuda' if torch.cuda.is_available() else 'cpu'):\n        \"\"\"\n        Initialize the SpeculativeDecoder with target and draft models.\n\n        Args:\n            target_model_name (str): The name or path of the target (larger) model.\n            draft_model_name (str): The name or path of the draft (smaller) model.\n            device (str): The device to run the models on. Defaults to 'cuda' if available, else 'cpu'.\n        \"\"\"\n        \n        self.device = device\n        self.Mp = AutoModelForCausalLM.from_pretrained(target_model_name).to(self.device)\n        self.Mq = AutoModelForCausalLM.from_pretrained(draft_model_name).to(self.device)\n        self.tokenizer = AutoTokenizer.from_pretrained(target_model_name)\n        self.no_accepted_tokens = 0\n        self.alpha = 0 \n        \n        if self.tokenizer.pad_token is None:\n            self.tokenizer.pad_token = self.tokenizer.eos_token\n        \n        self.Mp.eval()\n        self.Mq.eval()\n\n    @staticmethod\n    def sample(logits, temperature, top_k, top_p):\n        \n        \"\"\"\n        Adjust logits for sampling based on temperature, top-k, and top-p parameters.\n\n        Args:\n            logits (torch.Tensor): The input logits.\n            temperature (float): The temperature for sampling.\n            top_k (int): The number of top tokens to consider for top-k sampling.\n            top_p (float): The cumulative probability threshold for top-p sampling.\n\n        Returns:\n            torch.Tensor: The adjusted probability distribution.\n        \"\"\"\n        \n        if temperature <= 1e-6:\n            return F.one_hot(logits.argmax(dim=-1), num_classes=logits.size(-1)).float()\n        \n        logits = logits / temperature\n        \n        if top_k > 0:\n            top_k = min(top_k, logits.size(-1))\n            indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n            logits[indices_to_remove] = float('-inf')\n        \n        if top_p < 1.0:\n            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n            cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n            sorted_indices_to_remove = cumulative_probs > top_p\n            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n            sorted_indices_to_remove[..., 0] = 0\n            indices_to_remove = sorted_indices_to_remove.scatter(dim=-1, index=sorted_indices, src=sorted_indices_to_remove)\n            logits[indices_to_remove] = float('-inf')\n        \n        return F.softmax(logits, dim=-1)\n\n    def generate(self, prompt, temperature=1.0, top_k=0, top_p=1.0, initial_gamma=3, max_new_tokens=50):\n        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.device)\n        attention_mask = torch.ones_like(input_ids)\n\n        gamma = initial_gamma  # Start with initial gamma value\n        min_gamma, max_gamma = 1, 10  # Define min and max bounds for gamma\n        acceptance_threshold_high, acceptance_threshold_low = 0.8, 0.3  # Thresholds for adjusting gamma\n        betas = []\n        gamma_values = []  # List to store gamma values at each step\n        self.no_accepted_tokens = 0\n\n        for _ in range(0, max_new_tokens, gamma + 1):\n            gamma_values.append(gamma)  # Append current gamma value\n\n            # Draft model generation\n            with torch.no_grad():\n                draft_outputs = self.Mq.generate(\n                    input_ids,\n                    attention_mask=attention_mask,\n                    max_new_tokens=gamma,\n                    do_sample=True,\n                    temperature=temperature,\n                    top_k=top_k,\n                    top_p=top_p,\n                    return_dict_in_generate=True,\n                    output_scores=True,\n                    pad_token_id=self.tokenizer.pad_token_id,\n                )\n\n            draft_tokens = draft_outputs.sequences[:, input_ids.size(1):]\n            draft_probs = torch.stack(draft_outputs.scores).softmax(-1)\n\n            # Target model forward pass\n            with torch.no_grad():\n                target_outputs = self.Mp(\n                    torch.cat([input_ids, draft_tokens], dim=1),\n                    attention_mask=torch.cat([attention_mask, torch.ones_like(draft_tokens)], dim=1),\n                    return_dict=True,\n                )\n\n            target_logits = target_outputs.logits[:, input_ids.size(1)-1:-1]\n            target_probs = self.sample(target_logits, temperature, top_k, top_p)\n\n            # Speculative sampling and acceptance calculation\n            accepted_tokens = []\n            num_accepted = 0\n            for i in range(min(gamma, draft_tokens.size(1))):\n                draft_token = draft_tokens[:, i]\n                draft_prob = draft_probs[i].gather(-1, draft_token.unsqueeze(-1)).squeeze(-1)\n                target_prob = target_probs[:, i].gather(-1, draft_token.unsqueeze(-1)).squeeze(-1)\n\n                accept_prob = torch.min(torch.ones_like(target_prob), target_prob / draft_prob)\n                if torch.rand(1, device=self.device) < accept_prob:\n                    accepted_tokens.append(draft_token)\n                    num_accepted += 1\n                else:\n                    break\n\n            # Adjust gamma based on acceptance rate\n            self.no_accepted_tokens += len(accepted_tokens) + 1\n            acceptance_rate = num_accepted / gamma\n            betas.append(acceptance_rate)\n            \n            if acceptance_rate > acceptance_threshold_high and gamma < max_gamma:\n                gamma += 1\n            elif acceptance_rate < acceptance_threshold_low and gamma > min_gamma:\n                gamma -= 1\n\n            # Append accepted tokens and move to the next input sequence\n            if num_accepted < draft_probs.size(1):\n                accepted_tokens.append(draft_tokens[:, num_accepted])\n            else:\n                next_token = torch.multinomial(target_probs[:, -1], num_samples=1)\n                accepted_tokens.append(next_token)\n\n            new_tokens = torch.cat([token.view(1, 1) for token in accepted_tokens], dim=1)\n\n            input_ids = torch.cat([input_ids, new_tokens], dim=1)\n            attention_mask = torch.cat([attention_mask, torch.ones_like(new_tokens)], dim=1)\n\n            if input_ids.size(1) - len(self.tokenizer.encode(prompt)) >= max_new_tokens:\n                break\n\n        self.alpha = sum(betas) / len(betas)\n        return self.tokenizer.decode(input_ids[0], skip_special_tokens=True), gamma_values\n\n\n    def target_generate_greedy(self, prompt, max_new_tokens=50):\n        \"\"\"\n        Generate text using standard greedy decoding with the target model.\n\n        Args:\n            prompt (str): The input prompt to start generation from.\n            max_new_tokens (int): The maximum number of new tokens to generate. Defaults to 50.\n\n        Returns:\n            str: The generated text.\n        \"\"\"\n        model_inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n        greedy_output = self.target_model.generate(**model_inputs, max_new_tokens=max_new_tokens)\n        return self.tokenizer.decode(greedy_output[0])\n\n    def draft_generate_greedy(self, prompt, max_new_tokens=50):\n        \"\"\"\n        Generate text using standard greedy decoding with the draft model.\n\n        Args:\n            prompt (str): The input prompt to start generation from.\n            max_new_tokens (int): The maximum number of new tokens to generate. Defaults to 50\n\n        Returns:\n            str: The generated text.\n        \"\"\"\n    \n        model_inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n        greedy_output = self.draft_model.generate(**model_inputs, max_new_tokens=max_new_tokens)\n        return self.tokenizer.decode(greedy_output[0])","metadata":{"execution":{"iopub.status.busy":"2024-11-20T20:21:17.403470Z","iopub.execute_input":"2024-11-20T20:21:17.403796Z","iopub.status.idle":"2024-11-20T20:21:17.424968Z","shell.execute_reply.started":"2024-11-20T20:21:17.403768Z","shell.execute_reply":"2024-11-20T20:21:17.424067Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"seed = 42\nmax_length = 128\nset_seed(seed)\ndataset = load_dataset('cnn_dailymail', '3.0.0')\n\nval_data = dataset['validation']\ntest_data = dataset['test']\nval_data = val_data.select(range(50))\ntest_data = test_data.select(range(50))\n\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ntokenizer.pad_token = tokenizer.eos_token\n\nval_dataset = CNNDailyMailGPT2Dataset(val_data, max_length)\ntest_dataset = CNNDailyMailGPT2Dataset(test_data, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T20:21:20.652811Z","iopub.execute_input":"2024-11-20T20:21:20.653397Z","iopub.status.idle":"2024-11-20T20:21:23.447078Z","shell.execute_reply.started":"2024-11-20T20:21:20.653355Z","shell.execute_reply":"2024-11-20T20:21:23.446383Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"model = SpeculativeDecoder(target_model_name='gpt2-large',\n                                  draft_model_name='distilgpt2',\n                                  device='cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-11-20T20:21:23.448718Z","iopub.execute_input":"2024-11-20T20:21:23.449576Z","iopub.status.idle":"2024-11-20T20:21:25.651131Z","shell.execute_reply.started":"2024-11-20T20:21:23.449533Z","shell.execute_reply":"2024-11-20T20:21:25.650449Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.ndimage import gaussian_filter1d  # For smoothing\n\ndef evaluate_speculative_decoding(dataset, spec_decoder, max_new_tokens=100, temperature=1.0, top_k=0, top_p=1.0, gamma=3):\n    total_time = 0\n    total_tokens_produced = 0\n    alphas = []\n    all_gamma_values = []  # Store gamma values across all samples\n\n    # Loop through each sample in the dataset\n    for i, sample in enumerate(tqdm(dataset, desc=\"Evaluating Speculative Decoding\")):\n        prompt = sample['input_text']  # Modify prompt as needed\n\n        # Perform speculative decoding and measure time and alpha\n        start_time = time.time()\n        generated_text, gamma_values = spec_decoder.generate(prompt, temperature=temperature, top_k=top_k, top_p=top_p, initial_gamma=gamma, max_new_tokens=max_new_tokens)\n        decoding_time = time.time() - start_time\n\n        total_time += decoding_time\n        total_time = total_time / spec_decoder.no_accepted_tokens\n#         total_tokens_produced += spec_decoder.no_accepted_tokens\n        alphas.append(spec_decoder.alpha)\n        all_gamma_values.extend(gamma_values)  # Collect gamma values for plotting\n\n    # Calculate overall metrics\n#     avg_time_per_sample = total_time / len(dataset)\n#     avg_tokens_per_sample = total_tokens_produced / len(dataset)\n    avg_alpha = np.mean(alphas)\n    \n    temp = total_time / len(dataset)\n    print(\"avg time taken by speculative decoding: \", temp)\n#     print(f\"\\nEvaluation Results on Test Dataset:\")\n#     print(f\"Average time per sample: {avg_time_per_sample:.2f} seconds\")\n    print(f\"Average alpha (acceptance probability): {avg_alpha:.2f}\")\n#     print(f\"Average time per token: {total_time / total_tokens_produced:.4f} seconds\")\n    \n\n    # Smoothing gamma values for a cleaner plot\n    smoothed_gamma_values = gaussian_filter1d(all_gamma_values, sigma=2)  # Adjust sigma for more/less smoothing\n\n    # Plot gamma values\n    plt.figure(figsize=(12, 6))\n    plt.plot(smoothed_gamma_values, label=\"Smoothed Gamma Value\", color='blue', linewidth=2)\n    plt.scatter(range(len(all_gamma_values)), all_gamma_values, s=10, color='red', alpha=0.6, label=\"Original Gamma Values\")\n    plt.axhline(np.mean(all_gamma_values), color='green', linestyle='--', linewidth=1, label=\"Mean Gamma Value\")\n    plt.grid(alpha=0.3)\n    plt.xlabel(\"Generation Step\", fontsize=12)\n    plt.ylabel(\"Gamma\", fontsize=12)\n    plt.title(\"Change in Gamma Value Over Generation Steps\", fontsize=14)\n    plt.legend(fontsize=10)\n    plt.tight_layout()\n    plt.show()\n\n    return {\n        \"avg_time_per_sample\": avg_time_per_sample,\n        \"avg_tokens_per_sample\": avg_tokens_per_sample,\n        \"avg_alpha\": avg_alpha,\n    }","metadata":{"execution":{"iopub.status.busy":"2024-11-20T20:21:26.962696Z","iopub.execute_input":"2024-11-20T20:21:26.963020Z","iopub.status.idle":"2024-11-20T20:21:26.972433Z","shell.execute_reply.started":"2024-11-20T20:21:26.962991Z","shell.execute_reply":"2024-11-20T20:21:26.971514Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Run evaluation\nresults = evaluate_speculative_decoding(test_dataset, model)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T20:21:28.001933Z","iopub.execute_input":"2024-11-20T20:21:28.002224Z","iopub.status.idle":"2024-11-20T20:22:40.356077Z","shell.execute_reply.started":"2024-11-20T20:21:28.002197Z","shell.execute_reply":"2024-11-20T20:22:40.355265Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Evaluating Speculative Decoding: 100%|██████████| 50/50 [01:11<00:00,  1.44s/it]\n","output_type":"stream"},{"name":"stdout","text":"avg time taken by speculative decoding:  0.0007961923878542665\nAverage alpha (acceptance probability): 0.35\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"### Beam Search","metadata":{}},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SpeculativeDecoder:\n    \"\"\"\n    A class implementing speculative decoding for language models.\n\n    This class uses a larger target model and a smaller draft model to perform\n    speculative decoding, potentially speeding up text generation.\n\n    Attributes:\n        device (str): The device to run the models on ('cuda' or 'cpu').\n        target_model (AutoModelForCausalLM): The larger, more accurate language model.\n        draft_model (AutoModelForCausalLM): The smaller, faster language model for draft predictions.\n        tokenizer (AutoTokenizer): The tokenizer for both models.\n    \"\"\"\n    \n\n    def __init__(self, target_model_name, draft_model_name, device='cuda' if torch.cuda.is_available() else 'cpu'):\n        \"\"\"\n        Initialize the SpeculativeDecoder with target and draft models.\n\n        Args:\n            target_model_name (str): The name or path of the target (larger) model.\n            draft_model_name (str): The name or path of the draft (smaller) model.\n            device (str): The device to run the models on. Defaults to 'cuda' if available, else 'cpu'.\n        \"\"\"\n        \n        self.device = device\n        self.Mp = AutoModelForCausalLM.from_pretrained(target_model_name).to(self.device)\n        self.Mq = AutoModelForCausalLM.from_pretrained(draft_model_name).to(self.device)\n        self.tokenizer = AutoTokenizer.from_pretrained(target_model_name)\n        self.no_accepted_tokens = 0\n        self.alpha = 0 \n        \n        if self.tokenizer.pad_token is None:\n            self.tokenizer.pad_token = self.tokenizer.eos_token\n        \n        self.Mp.eval()\n        self.Mq.eval()\n\n    @staticmethod\n    def sample(logits, temperature, top_k, top_p):\n        \n        \"\"\"\n        Adjust logits for sampling based on temperature, top-k, and top-p parameters.\n\n        Args:\n            logits (torch.Tensor): The input logits.\n            temperature (float): The temperature for sampling.\n            top_k (int): The number of top tokens to consider for top-k sampling.\n            top_p (float): The cumulative probability threshold for top-p sampling.\n\n        Returns:\n            torch.Tensor: The adjusted probability distribution.\n        \"\"\"\n        \n        if temperature <= 1e-6:\n            return F.one_hot(logits.argmax(dim=-1), num_classes=logits.size(-1)).float()\n        \n        logits = logits / temperature\n        \n        if top_k > 0:\n            top_k = min(top_k, logits.size(-1))\n            indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n            logits[indices_to_remove] = float('-inf')\n        \n        if top_p < 1.0:\n            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n            cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n            sorted_indices_to_remove = cumulative_probs > top_p\n            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n            sorted_indices_to_remove[..., 0] = 0\n            indices_to_remove = sorted_indices_to_remove.scatter(dim=-1, index=sorted_indices, src=sorted_indices_to_remove)\n            logits[indices_to_remove] = float('-inf')\n        \n        return F.softmax(logits, dim=-1)\n\n    def generate_beam_search(\n        self, \n        prompt: str, \n        w: int, \n        u: int, \n        gamma: int, \n        max_new_tokens: int = 100\n    ) -> List[str]:\n\n        \"\"\"\n        Generate text using speculative beam search.\n\n        Args:\n            prompt (str): The input prompt to start generation from.\n            w (int): The original beam width for the target model (Mp).\n            u (int): The beam width for the approximation model (Mq), where u >= w.\n            gamma (int): The number of speculative steps.\n            max_new_tokens (int): The maximum number of new tokens to generate. Defaults to 100.\n\n        Returns:\n            List[str]: The list of generated sequences.\n        \"\"\"\n        stime = time.time()\n        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.device)\n        attention_mask = torch.ones_like(input_ids)\n\n        # Initialize beams\n        beams = [(input_ids, attention_mask, 0.0)]  # List of tuples: (input_ids, attention_mask, cumulative_log_prob)\n\n        for step in range(max_new_tokens):\n            all_candidates = []\n            for beam_idx, (beam_input_ids, beam_attention_mask, beam_log_prob) in enumerate(beams):\n                with torch.no_grad():\n                    outputs = self.Mq.generate(\n                        input_ids=beam_input_ids,\n                        attention_mask=beam_attention_mask,\n                        max_new_tokens=gamma,\n                        num_beams=u,\n                        do_sample=False,\n                        return_dict_in_generate=True,\n                        output_scores=True,\n                        pad_token_id=self.tokenizer.pad_token_id,\n                    )\n\n                # Collect candidates\n                for i in range(u):\n                    candidate_ids = outputs.sequences[i, beam_input_ids.size(1):]  # New tokens\n                    candidate_log_prob = outputs.scores[0][i].item()  # Assuming log probabilities\n                    all_candidates.append((candidate_ids, beam_attention_mask, beam_log_prob + candidate_log_prob))\n\n            # Rank all candidates based on cumulative log probability\n            all_candidates = sorted(all_candidates, key=lambda x: x[2], reverse=True)\n            # Select top w candidates\n            beams = all_candidates[:w]\n\n            # Speculative verification with target model (Mp)\n            # For each candidate, check if it's within topw (Mp)\n            verified_beams = []\n            for candidate_ids, candidate_attention_mask, candidate_log_prob in beams:\n                # Concatenate prompt with candidate\n                full_input_ids = torch.cat([input_ids, candidate_ids.unsqueeze(0)], dim=1)\n                full_attention_mask = torch.cat([attention_mask, torch.ones_like(candidate_ids).unsqueeze(0)], dim=1)\n\n                with torch.no_grad():\n                    target_outputs = self.Mp(full_input_ids, attention_mask=full_attention_mask, return_dict=True)\n                    target_logits = target_outputs.logits[:, -1, :]  # Logits for the last token\n                    target_probs = F.softmax(target_logits, dim=-1)\n                    topw_probs, topw_indices = torch.topk(target_probs, k=w, dim=-1)\n\n                # Check if candidate is within topw (Mp)\n                # Since beam search involves sequences, ensure the last token is in topw\n                candidate_token = candidate_ids[-1].unsqueeze(0)\n                if candidate_token in topw_indices:\n                    verified_beams.append((full_input_ids, full_attention_mask, candidate_log_prob))\n\n            # Update beams with verified candidates\n            beams = verified_beams[:w]\n\n            if not beams:\n                print(\"No beams passed the verification step.\")\n                break\n\n            # Print current beams\n            print(f\"Step {step + 1}:\")\n            for beam_input_ids, beam_attention_mask, beam_log_prob in beams:\n                generated_text = self.tokenizer.decode(beam_input_ids[0], skip_special_tokens=True)\n                print(f\"Beam: {generated_text} | Log Prob: {beam_log_prob}\")\n            print(\"-------------------------------\")\n\n        total_time = time.time() - stime\n        print(f\"\\nTotal time taken for beam search: {total_time:.2f} s\")\n\n        # Decode final beams\n        generated_sequences = [self.tokenizer.decode(beam_input_ids[0], skip_special_tokens=True) for beam_input_ids, _, _ in beams]\n        return generated_sequences\n\n\n    def generate(self, prompt, temperature=1.0, top_k=0, top_p=1.0, initial_gamma=3, max_new_tokens=50):\n            \n            \"\"\"\n            Generate text using speculative decoding with a dynamic gamma adjustment.\n\n            Args:\n                prompt (str): The input prompt to start generation from.\n                temperature (float): The temperature for sampling. Defaults to 1.0.\n                top_k (int): The number of top tokens to consider for top-k sampling. Defaults to 0 (disabled).\n                top_p (float): The cumulative probability threshold for top-p sampling. Defaults to 1.0 (disabled).\n                initial_gamma (int): The initial number of tokens to generate speculatively in each iteration. Defaults to 3.\n                max_new_tokens (int): The maximum number of new tokens to generate. Defaults to 50.\n\n            Returns:\n                str: The generated text.\n            \"\"\"\n            input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.device)\n            attention_mask = torch.ones_like(input_ids)\n\n            gamma = initial_gamma  # Start with initial gamma value\n            min_gamma, max_gamma = 1, 10  # Define min and max bounds for gamma\n            acceptance_threshold_high, acceptance_threshold_low = 0.8, 0.3  # Thresholds for adjusting gamma\n            betas = []\n            \n            for _ in range(0, max_new_tokens, gamma + 1):\n                # Draft model generation\n                with torch.no_grad():\n                    draft_outputs = self.Mq.generate(\n                        input_ids,\n                        attention_mask=attention_mask,\n                        max_new_tokens=gamma,\n                        do_sample=True,\n                        temperature=temperature,\n                        top_k=top_k,\n                        top_p=top_p,\n                        return_dict_in_generate=True,\n                        output_scores=True,\n                        pad_token_id=self.tokenizer.pad_token_id,\n                    )\n\n                draft_tokens = draft_outputs.sequences[:, input_ids.size(1):]\n                draft_probs = torch.stack(draft_outputs.scores).softmax(-1)\n\n                # Target model forward pass\n                with torch.no_grad():\n                    target_outputs = self.Mp(\n                        torch.cat([input_ids, draft_tokens], dim=1),\n                        attention_mask=torch.cat([attention_mask, torch.ones_like(draft_tokens)], dim=1),\n                        return_dict=True,\n                    )\n\n                target_logits = target_outputs.logits[:, input_ids.size(1)-1:-1]\n                target_probs = self.sample(target_logits, temperature, top_k, top_p)\n\n                # Speculative sampling and acceptance calculation\n                accepted_tokens = []\n                num_accepted = 0\n                for i in range(min(gamma, draft_tokens.size(1))):\n                    draft_token = draft_tokens[:, i]\n                    draft_prob = draft_probs[i].gather(-1, draft_token.unsqueeze(-1)).squeeze(-1)\n                    target_prob = target_probs[:, i].gather(-1, draft_token.unsqueeze(-1)).squeeze(-1)\n\n                    accept_prob = torch.min(torch.ones_like(target_prob), target_prob / draft_prob)\n                    if torch.rand(1, device=self.device) < accept_prob:\n                        accepted_tokens.append(draft_token)\n                        num_accepted += 1\n                    else:\n                        break\n\n                # Adjust gamma based on acceptance rate\n                acceptance_rate = num_accepted / gamma\n                betas.append(acceptance_rate)\n                if acceptance_rate > acceptance_threshold_high and gamma < max_gamma:\n                    gamma += 1\n                elif acceptance_rate < acceptance_threshold_low and gamma > min_gamma:\n                    gamma -= 1\n\n                # Append accepted tokens and move to the next input sequence\n#                 accepted_tokens.append(draft_tokens[:, num_accepted] if num_accepted < draft_probs.size(1) else next_token)\n                if num_accepted < draft_probs.size(1):\n                    accepted_tokens.append(draft_tokens[:, num_accepted])\n                else:\n                    # If num_accepted >= draft_probs.size(1), define next_token here\n                    next_token = torch.multinomial(target_probs[:, -1], num_samples=1)\n                    accepted_tokens.append(next_token)\n\n                new_tokens = torch.cat([token.view(1, 1) for token in accepted_tokens], dim=1)\n\n                input_ids = torch.cat([input_ids, new_tokens], dim=1)\n                attention_mask = torch.cat([attention_mask, torch.ones_like(new_tokens)], dim=1)\n\n                if input_ids.size(1) - len(self.tokenizer.encode(prompt)) >= max_new_tokens:\n                    break\n            self.alpha = sum(betas) / len(betas) \n\n            return self.tokenizer.decode(input_ids[0], skip_special_tokens=True)\n\n\n    def target_generate_greedy(self, prompt, max_new_tokens=50):\n        \"\"\"\n        Generate text using standard greedy decoding with the target model.\n\n        Args:\n            prompt (str): The input prompt to start generation from.\n            max_new_tokens (int): The maximum number of new tokens to generate. Defaults to 50.\n\n        Returns:\n            str: The generated text.\n        \"\"\"\n        model_inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n        greedy_output = self.target_model.generate(**model_inputs, max_new_tokens=max_new_tokens)\n        return self.tokenizer.decode(greedy_output[0])\n\n    def draft_generate_greedy(self, prompt, max_new_tokens=50):\n        \"\"\"\n        Generate text using standard greedy decoding with the draft model.\n\n        Args:\n            prompt (str): The input prompt to start generation from.\n            max_new_tokens (int): The maximum number of new tokens to generate. Defaults to 50\n\n        Returns:\n            str: The generated text.\n        \"\"\"\n    \n        model_inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n        greedy_output = self.draft_model.generate(**model_inputs, max_new_tokens=max_new_tokens)\n        return self.tokenizer.decode(greedy_output[0])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}